\documentclass[12pt]{article}
\usepackage[utf8]{inputenc} % pour le format de sortie
\usepackage[a4paper]{geometry}
\usepackage[T1]{fontenc}
\usepackage[english]{babel} % pour les accents
\usepackage{csquotes}
\usepackage{enumitem}
\usepackage{amssymb,amsmath,amsthm, amsfonts} % math libraries (amsthm : unumbered theorems)
\usepackage{mathtools} % for psmallmatrix
\usepackage{fancyhdr,multicol,accents, bbm,subcaption,caption,float,verbatim}
\usepackage[all]{xy} % for diagrams with arrows
\usepackage{tikz-cd} % for diagrams with arrows
\usepackage{graphicx} % to manage images
\usepackage{titlesec}
\usepackage{hyperref} % for hyperlinks to refs or bibliography
\usepackage{indentfirst} % for indenting the first line of a paragraph
\usepackage{optidef}
\usepackage{biblatex} % for bibliography
\usepackage{bookmark}
% \addbibresource{refs.bib}

% Margins, font size =====================================================================================================================
%\oddsidemargin = 0.5cm \evensidemargin = 0.5cm \textwidth = 6.3in
%\oddsidemargin = 1.2cm \evensidemargin = 1.2cm \textwidth = 6.3in
%\textheight =8.6in
\geometry{
	a4paper,
	total={170mm,257mm},
	left=20mm,
	top=20mm,
}

% Sections (theorems, propositions, lemmas…) =====================================================================================================================
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem*{conjecture}{\bf Conjecture}
\newtheorem{proposition}[theorem]{Proposition}
% \numberwithin{theorem}{section} % To display the section number in the theorem

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\newtheorem{exercise}{Exercise}
\newtheorem*{solution}{Solution}
\newtheorem*{answer}{Answer}
\newtheorem*{claim}{Claim}

\theoremstyle{remark}
\newtheorem*{theoremno}{{\bf Theorem}}
\newtheorem*{remark}{Remark}
\newtheorem*{example}{Example}
\newtheorem*{hint}{Hint}



% Commands =====================================================================================================================
\def\bb#1{\mathbb{#1}}
\def\cal#1{\mathcal{#1}}
\def\frak#1{\mathfrak{#1}}
\def\rm#1{\mathrm{#1}}
\def\bf#1{\mathbf{#1}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\K}{\mathbb{K}}
\newcommand{\bbP}{\mathbb{P}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\calP}{\mathcal{P}}
\newcommand{\G}{\mathcal{G}}
\newcommand{\calL}{\mathcal{L}}
\newcommand{\calC}{\mathcal{C}}
\newcommand{\calN}{\mathcal{N}}
\newcommand{\calF}{\mathcal{F}}
\newcommand{\calE}{\mathcal{E}}
\newcommand{\frakA}{\mathfrak{A}}
\newcommand{\frakS}{\mathfrak{S}}
\newcommand{\esp}{\mathbb{E}}
% \P = caracs spéciaux,\S = paragraphe, \L = L barre

% Existe déjà : ker, partie Im, Re, min, max, inf, sup, log, exp, sin, sinh, cos, cosh,, tan lim, liminf, limsup
\DeclareMathOperator{\Id}{Id}
\DeclareMathOperator{\Hom}{Hom}
\DeclareMathOperator{\Ima}{Im}
\DeclareMathOperator{\Homeo}{Homeo}
\DeclareMathOperator{\Aut}{Aut}
\DeclareMathOperator{\Bij}{Bij}
\DeclareMathOperator{\Isom}{Isom}
\DeclareMathOperator{\GL}{GL}
\DeclareMathOperator{\End}{End}
\DeclareMathOperator{\rang}{rang}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\vol}{vol}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\var}{Var}
\DeclareMathOperator{\erf}{erf}
\DeclareMathOperator{\spec}{spec}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\pgcd}{pgcd}
\DeclareMathOperator{\pgdc}{pgdc}

% Lois de probabilités
\DeclareMathOperator{\Geom}{Geom}
\DeclareMathOperator{\Bin}{Bin}
\DeclareMathOperator{\Exp}{Exp}
\DeclareMathOperator{\Ber}{Ber}
\DeclareMathOperator{\Student}{Student}
\DeclareMathOperator{\Poi}{Poi}
\newcommand{\czero}{\calC^0}
\newcommand{\cone}{\calC^1}
\newcommand{\ctwo}{\calC^2}
\newcommand{\cinf}{\calC^{\infty}}
\newcommand{\bigpeter}[1]{\Big\langle#1\Big\rangle}
\newcommand{\peter}[1]{\langle#1\rangle}
\newcommand{\transp}[1]{#1^t}
\newcommand{\series}[2]{\sum_{#1}^{\infty}#2}
\newcommand{\intt}[4]{\int_{#1}^{#2}#3\mathrm{d}#4}
\newcommand{\ddt}[1]{\frac{\mathrm{d}#1}{\mathrm{dt}}}
\newcommand{\deldt}[1]{\frac{\partial#1}{\partial\mathrm{t}}}
\newcommand{\rmd}[1]{\mathrm{d}#1}
\newcommand{\inv}[1]{#1^{-1}}
\newcommand{\dx}{\rmd x}
\newcommand{\dy}{\rmd y}
\newcommand{\dz}{\rmd z}
\newcommand{\dt}{\rmd t}
\newcommand{\du}{\rmd u}
\newcommand{\dv}{\rmd v}
\newcommand{\ds}{\rmd s}
\newcommand{\dxy}{\rmd xy}
\newcommand{\dyz}{\rmd yz}
\newcommand{\dyx}{\rmd yx}
\newcommand{\dzy}{\rmd zy}
\newcommand{\dzx}{\rmd zx}
\newcommand{\dxz}{\rmd xz}
\newcommand{\gtinf}[1]{\underset{#1\to\infty}{\longrightarrow}}
\newcommand{\sm}[4]{\begin{psmallmatrix}#1&#2\\#3&#4\end{psmallmatrix}}
\newcommand{\map}[4]{
	\begin{matrix}
		#1&\to&#2\\#3&\mapsto&#4
	\end{matrix}
}


\title{Stability properties of Relaxed Recentered log-barrier function based Nonlinear MPC}
\author{Tudor Oancea}
\date{March 2022}

\begin{document}
\maketitle

\section{Introduction}
Given a controlled nonlinear dynamical system of the form $x^+=f(x,u)$ with state and control constraints $x\in\cal{X}\subseteq\R^{n_x},~u\in\cal{U}\subseteq\R^{n_u}$ and a fixed point $x^*$ for these dynamics, i.e. a point such that $f(x^*,0)=x^*$, the problem of \textit{stabilization} is to find a a feedback control law $\mu:\cal{X}\to\cal{U}$ such that $x^*$ is asymptoticall stable for the dynamical system $x^+=f(x,\mu(x))$.
Such a problem is usually tackled using \textit{optimal control}, and precisely \textit{model predictive control} (MPC), an algorithm that defines this feedback control as the solution to an optimization problem of the following form :
\begin{align}
	\begin{split}
		\label{NMPC}
		V_N(x)=\underset{\mathbf{x},\mathbf{u}}{\min} &\quad J_N(\mathbf{x},\mathbf{u})\\
		\text{s.t.} &\quad x_0=x\text{ and }x_{k+1}=f(x_k,u_k),~k=0,\dots,N-1\\
		&\quad x_k\in\cal{X},~k=0,\dots,N\\
		&\quad u_k\in\cal{U},~k=0,\dots,N-1
	\end{split}
\end{align}
Here $N$ is called the horizon size, $J_N$ is the cost function that is usually described with \textit{stage costs} $l:\cal{X}\times\cal{U}\to\R$ and \textit{final cost} $F:\cal{X}\to\R$ by 
$$J_N(\mathbf{x},\mathbf{u})=\sum_{k=0}^{N-1}l(x_k,u_k)~+~F(x_N)$$
The system is then controlled by applying the first value of the optimal control sequence to the system.\newline
In our work the follwoing assumptions will be made :
\begin{assumption}~
	\begin{itemize}[label=\textbullet]
		\item The function $f$ describing the dynamics is a general $C^2$ function, not necessarily linear.
		\item Without loss of generality, $x^*=0$. We can always come back to this case by defining new translated states $\tilde{x}:=x-x^*$ and new dynamics and new constraints accordingly by translation.
		\item $x^*=0\in\mathrm{int}\,\cal{X}$ and $0\in\mathrm{int}\,\cal{U}$
		\item The stage costs and the final costs are quadratic : $l(x,u)=x^TQx+u^TQu,~F(x)=x^TPx$ with $Q,R$ and $P$ positive definite matrices.
		This is very usual in MPC.
		\item The state and constraints sets are polytopic :
		\begin{align*}
			X=\left\{x\in\R^{n_x}~|~C_xx\leq d_x\text{ with }C_x\in\R^{q_x\times n_x}\text{ and }d_x\in\R^{q_x}\right\}\\
			U=\left\{u\in\R^{n_u}~|~C_uu\leq d_u\text{ with }C_u\in\R^{q_u\times n_u}\text{ and }d_u\in\R^{q_u}\right\}
		\end{align*}
		Up to defining additional states and/or controls and modifying the dynamics accordingly, this can always be achieved.
	\end{itemize}
\end{assumption}
The goal is usually to define the terminal cost $F(x)$ in such a way that the optimal value function $V_N$ is a \textit{Lyapunov function}, which would prove that $x^*=0$ is asymptotically stable for the system controlled by the MPC.
In some cases the authors also include \textit{terminal constraints} on the last state $x_N$ to ensure this stability, but here we are solely focusing on MPC with terminal costs and without terminal constraints.
\newline
Our work presents a new formulation that is based on this classical MPC framework and replaces the inequality constraints in the optimization problem (given by the state and control constraints) by some modified log-barrier functions added to the objective function.
To properly introduce this new formulation let's introduce the central notion of \textit{relaxed recentered log-barrier function}.

\section{Statement of the new formulation}
\begin{definition}
	Given a constraint of the form $c^Tx\leq d$, the associated \textit{log-barrier function} is defined as $-\log(d-c^Tx)$.
	Such a function is defined on the interior of feasible set of the constraint and becomes infinity near its boundary.
	For a set of polytopic constraints similar to the ones describes above, we can define the log-barrier for the state constraints as the sum of the log-barriers for each constraint :
	$$B_x(x)=\sum_{i=1}^{q_x}-\log(d_{x,i}-\mathrm{row}_i(C_x)x)$$

\end{definition}
\begin{definition}
	A \textit{weight recentered log-barrier function} for a set of polytopic constraints similar to the ones described above is of the form :
	$$B_x(x)=\sum_{i=1}^{q_x}(1+w_{x,i})\left[\log(d_{x,i})-\log(d_{x,i}-\mathrm{row}_i(C_x)x)\right]$$
	where the weights $w_{x,i}$ are defined as chosen such that $B_x(0)=0$ and $\nabla B_x(0)=0$.
\end{definition}
\begin{definition}
	A \textit{relaxed recentered log-barrier function} (RRLB function) is defined by :
	\begin{align*}
		B_x(x)&=\sum_{i=1}^{q_x}(1+w_{x,i})B_{x,i}(x)\\
		\text{ with }B_{x,i}(x)&=\begin{cases}
			\log(d_{x,1})-\log(d_{x,1}-\mathrm{row}_i(C_x)x)&\text{if }d_{x,i}-\mathrm{row}_i(C_x)x>\delta\\
			\beta(d_{x,1}-\mathrm{row}_i(C_x)x;\delta)&\text{ otherwise}
		\end{cases}
	\end{align*}
	where $0<\delta$ is a relaxation parameter and $\beta$ is a function that twice continuously extends the log-barrier function on $(-\infty,\delta]$.
	The simplest example of such a function is 
	$$\beta(z;\delta)=\frac{1}{2}\left[ \left( \frac{z-2\delta}{\delta} \right)^2-1 \right]-\log(\delta)$$
\end{definition}

\begin{lemma}
	\label{RRLB-quadratic-bound}
	The RRLB functions are upper bounded by quadratic functions.
\end{lemma}
\begin{proof}
	The proof is similar to the one of the Lemma 3 of %\cite{RRLB-linear-MPC}.
\end{proof}

\newpage
Now we can finally define our new MPC formulation as follows :
\begin{align}
	\begin{split}\label{RRLB-NMPC}
		\tilde{V}_N(x)=\underset{\mathbf{x},\mathbf{u}}{\min} &\quad \tilde{J}_N(\mathbf{x},\mathbf{u})\\
		\text{s.t.} &\quad x_0=x\text{ and }x_{k+1}=f(x_k,u_k),~k=0,\dots,N-1\\
	\end{split}
\end{align}
where the new objective function $\tilde{J}_N(\mathbf{x},\mathbf{u})=\sum_{k=0}^{N-1}\tilde{l}(x_k,u_k)~+~\tilde{F}(x_N)$ is defined using the new stage costs $\tilde{l}(x,u)=l(x,u)+\epsilon B_x(x)+\epsilon B_u(u)$ and the new terminal cost $\tilde{F}(x)=x^TPx$ for a certain matrix $P$ that will be determined later.
The barrier parameter $\epsilon$ has in theory the following interpretation : when it goes to zero, the solution of problem \ref{RRLB-NMPC} converges to the one of \ref{NMPC}.


\section{Theoretical properties of RRLB Nonlinear MPC}

\subsection{Nominal asymptotic stability}

\begin{lemma}
	\label{Lipchitzianity}
	Consider the problem \ref{RRLB-NMPC} and re-write it in a simpler way as 
	\begin{align*}
		\tilde{V}_N(x)=\underset{\mathbf{u}}{\min} &\quad J(x,\mathbf{u})\\
		\text{s.t.}&
	\end{align*}
	where $J(x,\mathbf{u})=\tilde{l}(x_0,u_0)+\tilde{l}(f(x_0,u_0),u_1)+\dots+\tilde{F}(f(f(...),u_{N-1}))$\,.
	If for a certain value for the initial state $x$ we denote by $\tilde{\mathbf{u}}(x)=(\tilde{u}_0(x),\dots,\tilde{u}_{N-1}(x))$ the optimal sequence of controls and we suppose that $D_\mathbf{u}J(x,\tilde{\mathbf{u}})=0$ and $\nabla_{\mathbf{u}\mathbf{u}}^2J(x, \tilde{\mathbf{u}})\succ 0$ (the matrix is positive definite) then :
	\begin{itemize}[label=\textbullet]
		\item $\forall k=0,\dots,N-1,\quad \|\tilde{u}_k(x)\|=O(\|x\|)$
		\item $\forall k=1,\dots,N,\quad \|\tilde{x}_k(x)\|=f(f(\dots,u_{k-2}),u_{k-1})=O(\|x\|)$
	\end{itemize}
\end{lemma}
\begin{proof}
	See appendix
\end{proof}

Now the main piece :

\begin{theorem}
	Let's consider the problem \ref{RRLB-NMPC} and assume the following :
	\begin{enumerate}
		\item When linearizing the system dynamics around the equilibrium and letting $A=D_xf(0,0),~B=D_uf(0,0)$, we suppose that the pair $(A,B)$ is stabilizable.
		This implies in particular that there exists a stabilizing cost $K$, i.e. a matrix such that $A_K:=A+BK$ only has eigenvalues in the unit disk.
		\item The matrix $P$ defining the terminal costs is the unique positive definite solution to the following Lyapunov equation :
		\begin{equation}
			P=A_K^TPA_K+\mu Q_K
		\end{equation}
		where $\mu>1$ and $Q_K=Q+\epsilon M_x+K^T(R+\epsilon M_u)K$\,.
		\item The matrix $P$ defining the terminal costs is the unique positive definite solution to the following modified Discrete Alegbraic Riccati Equation (DARE) :
		\begin{equation}
			\label{DARE}
			P=A^TPA-A^TPB\inv{(\underbrace{R+\epsilon M_u}_{=:\tilde{R}}+B^TPB)}B^TPA+\underbrace{Q+\epsilon M_x}_{=:\tilde{Q}}
		\end{equation}
		where $M_x:=\nabla_{xx}^2B_x(0),M_u:=\nabla_{uu}^2B_u(0)$.
		This equation can be re-written as :
		\begin{equation}
			\label{full-DARE}
			\begin{cases}
				P=(\underbrace{A+BK}_{=:A_K})^TP(\underbrace{A+BK}_{=:A_K})+\underbrace{\tilde{Q}+K^T\tilde{R}K}_{=:\tilde{Q}_K}&\\
				K=-\inv{(\tilde{R}+B^TPB)}B^TPA&
			\end{cases}
		\end{equation}
	\end{enumerate}	
	then if we use the same notations for the optimal controls and states as in the previous lemma, the origin is asymptotically stable for the dynamical system $x^+=f(x,\tilde{u}_0(x))$ for all initial state in a certain neighborhood of the origin.
\end{theorem}

\begin{remark}
	The proof of the existence and unicity of such a matrix $P$ is based on results on the Continuous Algebraic Riccati equation and the proof can be found in the appendix.
\end{remark}

\begin{proof}~
	Let's define the matrices $\hat{Q}=\nabla_{xx}^2\tilde{l}(0,0)=Q+\epsilon M_x,\hat{R}=\nabla_{uu}^2\tilde{l}(0,0)=R+\epsilon M_u$ and $\hat{l}(x,u)=x^T\hat{Q}x+u^T\hat{R}u=\tilde{l}(x,u)+O(\|x\|^3+\|u\|^3)$\,.
	With this definitions we have $\tilde{l}(x,Kx)=x^TQ_Kx+O(\|x\|^3)$\,.

	By the second assumption, we have 
	$$\tilde{F}(A_Kx)+\mu x^T Q_K x-\tilde{F}(x)=0,~\forall x\in\R^{n_x}$$
	We can use the same reasoning as in the book to show that $\tilde{F}$ is a local Lyapunov funnction, i.e. there exists a neighborhood $V$ of the origin such that $\forall x\in V$ :
	\begin{align*}
		\tilde{F}(f(x,Kx))+x^T Q_K x-\tilde{F}(x)&\leq 0\\
		% \Longleftrightarrow\tilde{F}(f(x,Kx))-\tilde{F}(x)+\tilde{l}(x,Kx)&\leq O(\|x\|^3)&\\
		\Longleftrightarrow\tilde{F}(f(x,Kx))-\tilde{F}(x)+\tilde{l}(x,Kx)&= O(\|x\|^3)
	\end{align*}

	Then if the initial state in problem \ref{RRLB-NMPC} is in $V$ \textbf{(and this set is forward invariant)}, every state $\tilde{x}_k(x)$ will be in $V$ too.
	
	Now using the optimal sequence of states and controls of the problem \ref{RRLB-NMPC} starting at $x$, we can construct a new feasible sequence for the problem starting at $\tilde{x}_1(x)$ as 
	$\mathbf{x}'=(\tilde{x}_1,\dots,\tilde{x}_N,f(\tilde{x}_N,K\tilde{x}_N))$ and $\mathbf{u}'=(\tilde{u}_1,\dots,\tilde{u}_{N-1},K\tilde{x}_N)$ \,.
	Then we have :
	$$\tilde{V}_N(\tilde{x}_1)\leq\tilde{J}_N(\mathbf{x}',\mathbf{u}')=\underbrace{\tilde{J}_N(\tilde{\mathbf{x}},\tilde{\mathbf{u}})}_{=\tilde{V}_N(x)}~\underbrace{\underbrace{-\tilde{l}(x,\tilde{u}_0)}_{=O(\|x\|^2)}+\underbrace{\tilde{F}(f(\tilde{x}_N,K\tilde{x}_N))-\tilde{F}(\tilde{x}_N)+\tilde{l}(\tilde{x}_N,K\tilde{x}_N) }_{=O(\|\tilde{x}_N\|^3)=O(\|x\|^3)} }_{\leq-c\|x\|^2\text{ in a nbh }W\subseteq V}\checkmark$$
	
	It is easy to show that $\tilde{V}_N$ is lower and upper bounded by coercive quadratic functions (see appendix), so that $\tilde{V}_N$ is a Lyapunov function in $W$\,.~\checkmark

\end{proof}

\subsection{Constraints violation guarantees}

\section{Numerical extensions}

\subsection{Real Time Iteration methods}
\subsubsection{Asymptotic stability of RTI scheme}
\subsubsection{Numerical experiments}

\subsection{Parallelization}
\subsubsection{Numerical experiments}

\section{Appendix}
% \printbibliography
\begin{proof}[Proof of lemma \ref{Lipchitzianity}]

\end{proof}

\begin{lemma}[Existence an Unicity of solution to the Lyapunov equation]
	
\end{lemma}

\begin{proof}
	
\end{proof}

\begin{lemma}[Coercive quadratic lower and upper bounds for objective value function]

\end{lemma}

\end{document}