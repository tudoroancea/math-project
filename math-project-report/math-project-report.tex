\documentclass[12pt]{article}
\usepackage[utf8]{inputenc} % pour le format de sortie
\usepackage[a4paper]{geometry}
\usepackage[T1]{fontenc}
\usepackage[english]{babel} % pour les accents
\usepackage{csquotes}
\usepackage{enumitem}
\usepackage{amssymb,amsmath,amsthm, amsfonts} % math libraries (amsthm : unumbered theorems)
\usepackage{mathtools} % for psmallmatrix
\usepackage{fancyhdr,multicol,accents, bbm,subcaption,caption,float,verbatim}
\usepackage[all]{xy} % for diagrams with arrows
\usepackage{tikz-cd} % for diagrams with arrows
\usepackage{graphicx} % to manage images
\usepackage{titlesec}
\usepackage{hyperref} % for hyperlinks to refs or bibliography
\usepackage{indentfirst} % for indenting the first line of a paragraph
\usepackage{optidef}
\usepackage[backend=bibtex]{biblatex} % for bibliography
\usepackage{bookmark}
\addbibresource{refs.bib}

\include{predefs}

\title{Study of Relaxed Recentered Log-Barrier function based Nonlinear Model Predictive Control}
\author{Tudor Oancea}
\date{March 2022}

\begin{document}
\maketitle

\begin{abstract}
	In this project, we investigate the use of relaxed logarithmic barrier functions in the context of nonlinear model predictive control.
	We base our work on the one of C. Feller and C. Ebenbauer in \cite{RRLB-linear-MPC} and use one of their globally stabilizing schemes with terminal costs and without terminal sets.
	We partially extend the results on the nominal asymptotic stability of the corresponding closed-loop system and the constraint satisfaction guarantees to the case of nonlinear dynamics and show that they are satisfied only in a neighborhood of the target state.
	The theoretical results are complemented by numerical illustrations based on RTI and SQP algorithms.
\end{abstract}

\section{Introduction}
\textit{Control theory} can simply be defined as the study of a generally dynamical system whose state evolution that we can influence by the means of external parameters called \textit{controls}, or \textit{inputs}.
This theory is a very important one in numerous fields of engineering such as robotics, mechanical or chemical engineering where problems such as stabilizing a chemical reaction at a certain temperature or making an autonomous car follow the road are common.

An important subfield of control theory is \textit{optimal control} (OC), which aims at finding a \textit{control law}, i.e. a way to control a system in order to attain a certain goal, by formulating and solving an optimization problem.
For example, if one wants to stabilize the state around a certain target, or reference point that is constant in time, one will want to choose a control law that will minimize the distance between the future state (that depends on the current state and the chosen control) and the target state.
This problem of \textit{stabilization} will be the one we will consider in this paper, but it is interesting to know there are other problems for which OC is applicable, such as path tracking or optimal trajectory generation. 

One of the most important (family of) algorithm(s) of OC is \textit{Model Predictive Control}, or MPC. 
This procedure uses the knowledge of the system \textit{dynamic model} (the equation governing its evolution) to compute an control law that also takes the future into account.
More precisely, the control law is computed for a certain interval in time called the \textit{horizon}, and the cost along this whole horizon is minized.
In some sense, the controller won't take decisions it will regret afterwards.
MPC has many advantages over other classical control strategies, such as the ability to handle several control parameters and to take into consideration constraints on the states and the controls (by solving a \textit{constrained} optimization problem). These are very important in practice because any real-life system has physical limitations (e.g. the maximum speed of a car, the maximum torque of a motor, etc.).
We will properly introduce the mathematical formulation of MPC and the theoretical tools used to study it in section \ref{sec:background-material}.

In section \ref{sec:RRLB-MPC} we will introduce a different formulation in which (most of) the state and control constraints are replaced with a penalty added to the cost function.
Such penalties are common in Interior Point methods and are usually log-barrier functions.
These functions have several drawbacks, such as the fact that they are only defined in the interior of the feasible set.
In this paper we will introduce a relaxed version of these functions called \textit{Relaxed Recentered Log-Barrier functions}, or \textit{RRLB functions}. 
They extend regular log-barrier functions to the whole space and yield a convex optimization problem that is in general much easier to solve than the original one.
More details on the upsides of RRLB functions can be found in the Introduction of \cite{RRLB-linear-MPC}.

In the theoretical study of this new formulation that we will call \textit{RRLB MPC}, we will prove two major results : 
\begin{enumerate}
	\item When using the control law computed by the RRLB MPC, the corresponding closed-loop system asymptotically stabilizes at the target state. (see subsection \ref{sec:RRLB-nominal-stability}) This property will be called \textit{nominal stabilty}, to be differentiated of \textit{real-time stability} (see subsection \ref{sec:RRLB-real-time-stability}).
	\item In this formulation, the optimal solution of the optimization problem might yield states or controls that are not feasible in the original problem. However, if we start sufficiently close to the target state, this will never happen. (see subsection \ref{sec:constraints-satisfaction-guarantees})
\end{enumerate}

Finally, in section \ref{sec:numerical-extensions} we examine numercial aspects of the RRLB MPC.
In practice, the optimization problem is not solved exactly, and we can't necessarily guarantee the satisfaction of the previous results in practice. 
However, we will show that we can when using \textit{Real Time Iteration} methods (RTI, that correspond to using Sequential Quadratic Programming with only one iteration), which is quite common in practical implementations when the problem has to be solved online and with limited computation power.
All our results will in the end be illustrated with a classical benchmark problem for MPC schemes : the Continuously Stirred Tank Reactor (CSTR) system.

\section{Background material}\label{sec:background-material}

\subsection{What is MPC ?}\label{sec:what-is-MPC}

We are given a discrete-time controlled nonlinear dynamical system of the form $x(k+1)=f(x(k), u(k))$ (which we will usually denote $x^+=f(x,u)$) with state and control constraints $x(k)\in\cal{X}\subseteq\R^{n_x},~u(k)\in\cal{U}\subseteq\R^{n_u}$.
Our goal is to stabilize the system around a target state $x^*$ and a target control $u^*$, which have to be a fixed point of the system : $x^*=f(x^*, u^*)$\,.
To do that we will try to construct a \textit{state-feedback control law}, i.e. a function $\mu:\cal{X}\to\cal{U}$ such that $x^*$ is \textit{asymptotically stable} for the dynamical system $x^+=f(x,\mu(x))$ (which only depends on the state).
The exact definition of asymptotica stability and how to prove it is discussed in subsection \ref{sec:Lyapunov-stability-theory}.

An important simplification that is often made (and that we will use in this paper) is that we consider $x^*=0$ and $u^*=0$\,.
It is easy to verify that when this is not the case, we can just define new translated states $\hat{x}=x-x^*$ and new control $\hat{u}=u-u^*$ and consequently new dynamics, new constraints, etc.

To construct this control law $\mu$, we will solve the following opitmization problem :
\begin{align}
	\begin{split}
		\label{eq:NMPC}
		V_N(x)=\underset{\mathbf{x},\mathbf{u}}{\min} &\quad \sum_{k=0}^{N-1}l(x_k,u_k)~+~F(x_N)\\
		\text{s.t.} &\quad x_0=x\text{ and }x_{k+1}=f(x_k,u_k),~k=0,\dots,N-1\\
		&\quad x_k\in\cal{X},~k=0,\dots,N\\
		&\quad u_k\in\cal{U},~k=0,\dots,N-1
	\end{split}
\end{align}
A bit of vocabulary : $N$ is called the \textit{horizon length}, the function $l$ is the \textit{stage cost}, the function $F$ is the \textit{terminal cost} (its role will become clearer in next section) and the function $J_N(\mathbf{x},\mathbf{u})=\sum_{k=0}^{N-1}l(x_k,u_k)~+~F(x_N)$ is called the \textit{cost function}.

These costs have to be defined byt the user as a measure of the deviations from the target state and control (we recall they are 0).
Their fine tuning is of capital importance for the feasibility, robustness and performance of the MPC scheme, and it is a whole area of interest of control theory (which is out of the scope of this paper).
Then, during the experiment, we observe at a time $k$ the state $x(k)$.
We solve the MPC \ref{eq:NMPC} and find the optimal sequences of states and controls $$\mathbf{x}^*(x(k))=\left\{ x_0^*(x(k))=x(k),\dots,x_N^*(x(k))\right\},\quad \mathbf{u}^*(x(k))=\left\{ u_0^*(x(k)),\dots,u_{N-1}^*(x(k))\right\}$$
They represent the controls to apply at time $k,k+1,\dots,k+N-1$ and the states the system will be in after these controls are applied.
In a sense, we 'over-solve' the problem since we are actually only interested in $u_0^*(x(k))$ that will define our control law : 
$$\mu_{MPC}(x(k)):=u_0^*(x(k))$$
Since at time $k+1$ the horizon will have shifted, we say we solve the control problem in a \textit{receeding horizon} fashion.

\vspace{12pt}

This general form of the MPC is the one we will use, but other variants exist in which different state constraint, called \textit{terminal constraints}, are enforces on $x_N$\,.
We are also going to consider very specific form of costs and constraints : the costs will always be quadratic ($l(x,u)=x^TQx+u^TRu$ and $F(x)=x^TPx$ for some positive definite matrices $Q,R$ and $P$) and the (inequality) constraints will always be polytopic ($\cal{X}=\left\{x\in\R^{n_x}~|~C_xx\leq d_x\right\},~\cal{U}=\left\{u\in\R^{n_u}~|~C_uu\leq d_u\right\}$ for matrices $C_x,C_u$ and vectors $d_x,d_u$ of appropriate dimension).
These are very common in real-world applications.

\vspace{12pt}

Other variants of MPC are:
\begin{itemize}[label=\textbullet]
	\item \underline{the \textit{infinite horizon MPC}}: 
	\begin{align*}
		V_\infty(x)=\underset{\mathbf{x},\mathbf{u}}{\min} &\quad \sum_{k=0}^{\infty}l(x_k,u_k)\\
		\text{s.t.} &\quad x_0=x\text{ and }x_{k+1}=f(x_k,u_k),~k=0,\dots,N-1\\
		&\quad x_k\in\cal{X},~k=0,\dots,N\\
		&\quad u_k\in\cal{U},~k=0,\dots,N-1
	\end{align*}
	In real life applications, we virtually consider that the duration of the experiment is infinite, so this variant may seem more natural.
	However this opitmization problem is infinite-dimensional so not easily solvable in practice.
	The terminal costs in regular MPC can actually be interpreted as a proxy for the part of the inifinite horizon that is not considered, and they are usually chosen this way.

	\item\underline{the \textit{(infinite-horizon) Linear Quadratic Regulator}, or \textit{LQR}}:\newline
	it is basically an MPC with linear dynamics ($x^+=Ax+Bu$) and without state and control constraints.
	These problems are the most basic one can find and are deeply linked to \textit{(Discrete) Algebraic Riccati Equations}, or \textit{DARE}:
	\begin{equation}
		\label{eq:DARE-LQR}
		P=Q+A^TPA-A^TPB(R+B^TPB)^{-1}B^TPA
	\end{equation}
	The unique positive definite solution of this equation actually verifies $V_\infty(x)=x^TPx$ so it can be used to define the terminal costs of the finite horizon LQR problem.
	This equation also provides the stabilizing state-feedback control law of the infinite horizon LQR : $\mu(x)=Kx$ where $K=-(R+B^TPB)^{-1}B^TPA$\,.
	It is intersting to notice that in this case, the solution $P$ to the DARE also verifies the follwing equation called \textit{Lyapunov equation} :
	$$P=A_K^TPA_K+Q_K$$
	where $A_K:=A+BK$ corresponds the evolution of the controlled system ($x^+=Ax+B\mu(x)=(A+BK)x$) and $Q_K:=Q+K^TRK$ corresponds to cost of a stage $(x,Kx)$ ($l(x,Kx)=x^TQ+(Kx)^TR(Kx)=x^TQ_Kx$).

	More details on the properties of the DARE can be found in the appendix \ref{sec:DARE}.
\end{itemize}


\subsection{Lyapunov stability theory}\label{sec:Lyapunov-stability-theory}
In this subsection we present the necessary background in dynamical systems theory and in particular give more precise definitions of the stability properties we want to prove.
We will consider a general nonlinear dynamical system $x^+=g(x)$, whithout any control, since we remember that our goal is to construct the control as only depending on the state.

A state $x^*$ is said to be :
\begin{itemize}[label=\textbullet]
	\item \textit{locally stable} if $\forall\epsilon>0,\exists \delta>0$ s.t. $\|x(0)-x^*\|\leq\delta\implies\|x(k)-x^*\|\leq\epsilon,~\forall k\geq 0$\,.
	\item \textit{locally attractive} if $\|x(k)-x^*\|\underset{k\to\infty}{\longrightarrow}0$ for all $x(0)$ in a certain neighborhood of $x^*$\,.
	\item \textit{globally attractive} if $\|x(k)-x^*\|\underset{k\to\infty}{\longrightarrow}0$ for all $x(0)$ in $\cal{X}$\,.
	\item \textit{locally asymptotically stable}, or \textit{LAS}, if it is both locally stable and locally attractive.
	\item \textit{globally asymptotically stable}, or \textit{GAS}, if it is both stable and globally attractive.
\end{itemize}

It can be showed that a state $x^*$ is GAS (or a LAS), if we can find a function $V:\cal{X}\to\R$ such that $\forall x\in\cal{X}$ (respectively in a neighborhood of $x^*$):
\begin{align*}
	V(x)&\leq c_1\|x-x^*\|^2\\
	V(x)&\geq c_2\|x-x^*\|^2\\
	V(g(x))&\leq V(x)-c_3\|x-x^*\|^2
\end{align*}
Such a function is called a \textit{Lyapunov function}, and the last equation is called the \textit{descent property}, which is usually the one that is the harder to prove for a given candidate function.

\vspace{12pt}

In our case, the candidate function we are going to be interested in is the objective value function $V_N$ defined in \ref{eq:NMPC}.


\section{The RRLB MPC}\label{sec:RRLB-MPC}

In this section we will introduce the RRLB functions, formulate the RRLB MPC and recall the results proved in the linear case in \cite{RRLB-linear-MPC}.
As mentioned in the last section, we will suppose that $x^*=0\in\cal{X}^\circ$ and $u^*=0\in\cal{U}^\circ$.

\vspace{12pt}

First let's take a step back and recall what regular log-barrier functions are.
We will first give the definitions only for the states $x$, since they only depend on the constraint set and not on the actual quantity represented.

For a simple constraint of the form $c^Tx\leq d$, the associated \textit{log-barrier function} is defined as $-\log(d-c^Tx)$.
Such a function is defined on the interior of feasible set of the constraint and becomes infinity near its boundary.
For a set of polytopic constraints, we can define the log-barrier as the sum of the log-barriers for each constraint :
$$B_x(x)=\sum_{i=1}^{q_x}-\log(d_{x,i}-\mathrm{row}_i(C_x)x)$$
where $q_x$ is the number of constraints, or equivalently the numbers of rows in $C_x$\,.

A first interesting property we would like to add to our log-barrier function is the one of \textit{positive definiteness}, i.e. $B_x(x)>0,~\forall x\neq 0$ in a neighborhood of the origin.
To this end we introduce the notion of \textit{weight recentered log-barrier function} as defined in \cite{RLB} :
$$B_x(x)=\sum_{i=1}^{q_x}(1+w_{x,i})\left[\log(d_{x,i})-\log(d_{x,i}-\mathrm{row}_i(C_x)x)\right]$$
where the weights $w_{x,i}$ are defined as chosen such that $B_x(0)=0$ and $\nabla B_x(0)=0$.
It is shown in \cite{RLB} that such weights always exist and that this wight-recentered log-barrier function is also positive definite and upper-bounded by a quadratic.

The second important property we have to add is the existence on the whole space.
For a given \textit{relaxation parameter} $\delta>0$, we can define the \textit{relaxed recentered log-barrier function}, or \textit{RRLB} function as follows :
\begin{align}
	\begin{split}
		\label{RRLB}
		B_x(x)&=\sum_{i=1}^{q_x}(1+w_{x,i})B_{x,i}(x)\\
		\text{ with }B_{x,i}(x)&=\begin{cases}
			\log(d_{x,1})-\log(d_{x,1}-\mathrm{row}_i(C_x)x)&\text{if }d_{x,i}-\mathrm{row}_i(C_x)x>\delta\\
			\beta(d_{x,1}-\mathrm{row}_i(C_x)x;\delta)&\text{ otherwise}
		\end{cases}
	\end{split}
\end{align}
where $\beta$ is a twice continuously function that extends the log-barrier to a twice continuously differentiable function on $\R$.
The simplest example of such a function is 
$$\beta(z;\delta)=\frac{1}{2}\left[ \left( \frac{z-2\delta}{\delta} \right)^2-1 \right]-\log(\delta)$$
To ensure that this function still verifies $B_x(0)=0$ and $\nabla B_x(0)=0$, we need to choose $0<\delta\leq\min\left\{d_{x,1},\dots,d_{x,q_x},d_{u,1},\dots,d_{u,q_u}\right\}$\,, which is always possible if $0\in\cal{X}$ and $0\in\cal{U}$\,.

\vspace{24pt}

With all these definitions we can finally define the \textit{RRLB MPC} :
\begin{align}
	\begin{split}\label{eq:RRLB-NMPC}
		\tilde{V}_N(x)=\underset{\mathbf{x},\mathbf{u}}{\min} &\quad \tilde{J}_N(\mathbf{x},\mathbf{u})\\
		\text{s.t.} &\quad x_0=x\text{ and }x_{k+1}=f(x_k,u_k),~k=0,\dots,N-1\\
	\end{split}
\end{align}
where the new objective function $\tilde{J}_N(\mathbf{x},\mathbf{u})=\sum_{k=0}^{N-1}\tilde{l}(x_k,u_k)~+~\tilde{F}(x_N)$ is defined using the new stage costs $\tilde{l}(x,u)=l(x,u)+\epsilon B_x(x)+\epsilon B_u(u)$ and the new terminal cost $\tilde{F}(x)=x^TPx$ for another matrix $P$ that will be determined in such a way that the control law given by the MPC yields an asymptotically stable system.
The barrier parameter $\epsilon$ has in theory the following interpretation : when it goes to zero, the solution of problem \ref{eq:RRLB-NMPC} converges to the one of \ref{eq:NMPC}.
However, we will here consider it as fixed for simplicity.

\vspace{12pt}

When we consider the RRLB MPC \ref{eq:RRLB-NMPC} in the case of linear dynamics $x^+=Ax+Bu$, we know the two following theorems.

\begin{theorem}
	\label{nominal-stability-linear-case}
	Suppose that the pair $(A,B)$ is stabilizable\footnote{We did not discuss the notion of controllability and stabilizability in \ref{sec:what-is-MPC} because they do not play a direct role in our proofs. They are however very important in standard control theory and they are needed in the proofs of existence of DAREs. More on them in the appendix \ref{sec:controllability-stabilizability}}
	and that the matrix $P$ is chosen as the unique positive definite solution to the following modified DARE :
	$$P=A^TPA-A^TPB(R+\epsilon M_u+B^TPB)^{-1}B^TPA+Q+\epsilon M_x$$
	where $M_x=\nabla^2 B_x(0)$ and $M_u=\nabla^2 B_u(0)$\, are the hessian of the RRLB functions at the origin.

	Then for any initial state $x(0)\in\R^{n_x}$, the control law given by the MPC yields an asymptotically stable system.
	% TODO : add definition of stabilizable
\end{theorem}

\begin{theorem}
	\label{constraint-satisfaction-guarantee-linear-case}
	In the same conditions as previous theorem, there is a neighborhood $\cal{X}_N(\delta)$ of the origin such that for any initial state $x(0)\in\cal{X}_N(\delta)$, all the constraint will be satisfied along the closed-loop trajectories.
	Furthermore, the set $\cal{X}_N(\delta)$ is given explicitly by :
	$$\cal{X}_N(\delta)=\left\{x\in\cal{X}~|~\tilde{V}_N(x(0))-x(0)^TP_{LQR}x(0)\leq\min\{\beta_x(\delta),\beta_u(\delta)\}\right\}$$
	where $P_{LQR}$ is the solution to the classical DARE \ref{eq:DARE-LQR} and 
	$$\beta_x(\delta)=\underset{i,x}{\min}\left\{ B_x(x)~|~\mathrm{row}_i(C_xx)=d_{x,i} \right\},\quad \beta_u(\delta)=\underset{i,u}{\min}\left\{ B_u(u)~|~\mathrm{row}_i(C_uu)=d_{u,i} \right\}$$
\end{theorem}

Additional results were proven in the linear case, such as the existence of a procedure to find $\delta$ such that the maximum constraint violation along the closed-loop trajectories is bounded by a pre-defined tolerance.
In our nonlinear case however we will not be able to prove these more powerful results because of the lack of knowledge on the error terms that appear in the dynamics (see subsection \ref{sec:constraints-satisfaction-guarantees})

\section{Theoretical properties of RRLB Nonlinear MPC}\label{sec:RRLB-theoretical-properties}

In this section, we consider the RRLB MPC \ref{eq:RRLB-NMPC} with nonlinear dynamics and show that the results of the previous section hold locally, in a certain neighborhood of the origin.

From this point on, for an initial state $x\in\R^{n_x}$ we will denote by \newline
$\tilde{\mathbf{x}}(x)=\left\{ \tilde{x}_0(x)=x,\tilde{x}_1(x),\dots,\tilde{x}_N(x) \right\}$ and $\tilde{\mathbf{u}}(x)=\left\{ \tilde{u}_0(x),\tilde{u}_1(x),\dots,\tilde{u}_{N-1}(x) \right\}$ the optimal sequences of states and controls found by the RRLB MPC.

\subsection{Nominal asymptotic stability}\label{sec:RRLB-nominal-stability}

\begin{lemma}
	\label{thm:Lipchitzianity}
	Consider the RRLB MPC \ref{eq:RRLB-NMPC} and re-write it in a simpler way as 
	$$\tilde{V}_N(x)=\underset{\mathbf{u}}{\min} \quad J(x,\mathbf{u})$$
	where $J(x,\mathbf{u})=\tilde{l}(x_0,u_0)+\tilde{l}(f(x_0,u_0),u_1)+\dots+\tilde{F}(f(f(...),u_{N-1}))$\,.
	If we suppose that $D_\mathbf{u}J(x,\tilde{\mathbf{u}})=0$ and $\nabla_{\mathbf{u}\mathbf{u}}^2J(x, \tilde{\mathbf{u}})\succ 0$ (the matrix is positive definite) then :
	\begin{itemize}[label=\textbullet]
		\item $\forall k=0,\dots,N-1,\quad \|\tilde{u}_k(x)\|=O(\|x\|)$
		\item $\forall k=1,\dots,N,\quad \|\tilde{x}_k(x)\|=f(f(\dots,u_{k-2}),u_{k-1})=O(\|x\|)$
	\end{itemize}
\end{lemma}
\begin{proof}
	We can use the proof of the Theorem 4.2 in \cite{lectures-parametric-optimization} to argue that each $\tilde{x}_k(x)$ and $\tilde{u}_k$ is continuously differentiable on a neighborhood of the origin.
	Therefore, by continuity their gradient is bounded on this neighborhood and they are Lipchitz.
\end{proof}

Now our main result :

\begin{theorem}\label{thm:nominal-stability}
	Let's consider the problem \ref{eq:RRLB-NMPC} and assume the following :
	\begin{enumerate}
		\item the assumptions of lemma \ref{thm:Lipchitzianity}

		\item When linearizing the system dynamics around the equilibrium and letting $A=D_xf(0,0),~B=D_uf(0,0)$, we suppose that the pair $(A,B)$ is stabilizable.
		This implies in particular that there exists a stabilizing cost $K$, i.e. a matrix such that $A_K:=A+BK$ only has eigenvalues in the unit disk.
		
		\item The matrix $P$ defining the terminal costs is the unique positive definite solution to the following Lyapunov equation :
		\begin{equation*}
			P=A_K^TPA_K+\mu Q_K
		\end{equation*}
		where $\mu>1$ and $Q_K=Q+\epsilon M_x+K^T(R+\epsilon M_u)K$\,.
	\end{enumerate}	
	Then for all initial state in a certain neighborhood of the origin, the control law given by the RRLB MPC yields an asymptotically stable system, i.e. the origin is asymptotically stable for the dynamical system $x^+=f(x,\tilde{u}_0(x))$\,.
\end{theorem}

\begin{remark}~
	The matrix $K$ can be constructed using the DARE for the following modified infinite horizon LQR problem :
	\begin{align}
		\begin{split}\label{eq:inf-LQR}
			\underset{\mathbf{x},\mathbf{u}}{\min} &\quad \sum_{k=0}^\infty x_k^T(Q+\epsilon M_x)x_k+u_k^T(R+\epsilon M_u)u_k\\
			\text{s.t.} &\quad x_{k+1}=Ax_k+Bu_k,~k=0,\dots,N-1\\
		\end{split}
	\end{align}
	where $M_x=\nabla^2B_x(0)$ and $M_u=\nabla^2B_u(0)$, i.e.
	$$\begin{cases}
		K=-(R+B^T\Pi B)^{-1}B^T\Pi A&\\
		\Pi=A_K^T\Pi A_K+Q_K
	\end{cases}$$
	The only difference between this last equation and the Lyapunov equation in the statement of the theorem is the $\mu$ term.
	In theory it is very important, but in practice, we can actually take it very close to 1 and find $P$ and $K$ by solving 
	$$\begin{cases}
		K=-(R+B^TP B)^{-1}B^TP A&\\
		P=A_K^TP A_K+Q_K
	\end{cases}$$
	More on that in \ref{sec:RRLB-numerical-experiments}.
\end{remark}

\begin{proof}~
	To prove the result we will show that $\tilde{V}_N$ is a Lyapunov function in a certain neighborhood of the origin.

	First, by writing the Taylor expansion of the stage costs $\tilde{l}$ we can see that
	\begin{align*}
		\tilde{l}(x,u)&=x^T[\nabla_{xx}^2\tilde{l}(0,0)] x+u^T[\nabla_{uu}^2\tilde{l}(0,0)]u+O(\|x\|^3+\|u\|^3)\\
		&=x^T[Q+\epsilon M_x]x+u^T[R+\epsilon M_u]u+O(\|x\|^3+\|u\|^3)
	\end{align*}
	so $\tilde{l}(x,Kx)=x^TQ_Kx+O(\|x\|^3)$\,.
	By the second assumption, we also have $\forall x\in\R^{n_x}$:
	$$\tilde{F}(A_Kx)+\mu x^T Q_K x-\tilde{F}(x)=0$$
	We can use the same reasoning as in the paragraph 2.5.5 of \cite[MPC Theory, Computation and Design]{MPC-book} to show that $\tilde{F}$ is a local Lyapunov funnction, i.e. there exists a neighborhood of the origin such that $\forall x$ in it :
	\begin{align*}
		\tilde{F}(f(x,Kx))+x^T Q_K x-\tilde{F}(x)&\leq 0\\
		\Longleftrightarrow\tilde{F}(f(x,Kx))-\tilde{F}(x)+\tilde{l}(x,Kx)&= O(\|x\|^3)
	\end{align*}

	What's more, by previous lemma, the predicted states are all Lipschitz with respect to the initial state, so we can choose an even smaller neighborhood such that $\tilde{x}_N(x)$ is also in it.
	
	Now using the optimal sequence of states and controls of the RRLB MPC starting at $x$, we can construct new feasible sequences for the problem starting at $\tilde{x}_1(x)$ as \newline
	$\mathbf{x}'=(\tilde{x}_1,\dots,\tilde{x}_N,f(\tilde{x}_N,K\tilde{x}_N))$ and $\mathbf{u}'=(\tilde{u}_1,\dots,\tilde{u}_{N-1},K\tilde{x}_N)$\,.
	Then we have :
	$$\tilde{V}_N(\tilde{x}_1)\leq\tilde{J}_N(\mathbf{x}',\mathbf{u}')=\underbrace{\tilde{J}_N(\tilde{\mathbf{x}},\tilde{\mathbf{u}})}_{=\tilde{V}_N(x)}~\underbrace{\underbrace{-\tilde{l}(x,\tilde{u}_0)}_{=O(\|x\|^2)}+\underbrace{\tilde{F}(f(\tilde{x}_N,K\tilde{x}_N))-\tilde{F}(\tilde{x}_N)+\tilde{l}(\tilde{x}_N,K\tilde{x}_N) }_{=O(\|\tilde{x}_N\|^3)=O(\|x\|^3)} }_{\leq-c\|x\|^2\text{ in a smaller nbh }}\checkmark$$
	We have therefore shown the descent property of our candidate Lyapunov function $\tilde{V}_N$\,.

	Finally, it is easy to show that $\tilde{V}_N$ is lower and upper bounded by coercive quadratic functions (see appendix), so that $\tilde{V}_N$ is indeed a Lyapunov function in a small neighborhood around the origin.
\end{proof}

\subsection{Constraints satisfaction guarantees}\label{sec:constraints-satisfaction-guarantees}
This section follows closely the section IV.D of \cite{RRLB-linear-MPC} but gives more loose results that cannot take us as far.
In particular, will show that we can ensure the existence of a neighborhood around the origin such that if we start in it, the states and controls along the closed-loop simulation will never violate the constraints.
However, this neighborhood cannot be easily computed because of the generality of the considered dynamics.

% \begin{definition}
% 	For our RRLB functions $B_x$ and $B_u$ we can define :
% \end{definition}

\begin{lemma}
	\label{thm:RRLB-bounds-guarantees}
	Consider problem \ref{eq:RRLB-NMPC} and an initial state $x(0)$ in the neighborhood given by \ref{thm:nominal-stability}.
	Let's denote by $\left\{x(0),x(1),\dots\right\}$ and $\left\{u(0), u(1),\dots\right\}$ the closed-loop state and control trajectories (given by $u(k)=\tilde{u}_0(x(k)),~x(k+1)=f(x(k),u(k))$).
	Then $\forall k\geq 0$:
	\begin{align*}
		B_x(x(k))&\leq\frac{1}{\epsilon}\left(\tilde{V}_N(x(0))-x(0)^TP_{LQR}x(0)-\sum_{k=0}^\infty\eta(x(k))\right)\\
		B_u(u(k))&\leq\frac{1}{\epsilon}\left(\tilde{V}_N(x(0))-x(0)^TP_{LQR}x(0)-\sum_{k=0}^\infty\eta(x(k))\right)
	\end{align*}
	where $P_{LQR}$ is the solution to the DARE associated \ref{eq:inf-LQR} and $\eta(x)=\tilde{l}(\tilde{x}_N(x),K\tilde{x}_N(x))+\tilde{F}(\tilde{x}_N(x))-\tilde{F}(f(\tilde{x}_N(x), K\tilde{x}_N(x)))$.
\end{lemma}

\begin{proof}
	In the proof of theorem \ref{thm:nominal-stability} we showed that $\forall k\geq 0$:
	\begin{multline*}
		\tilde{V}_N(x(k+1))-\tilde{V}_N(x(k))\leq-\tilde{l}(x(k),u(k))+\tilde{l}(\tilde{x}_N(x(k)), K\tilde{x}_N(x(k)))\\
		-\tilde{F}(\tilde{x}_N(x(k)))+\tilde{F}(f(\tilde{x}_N(x(k)),\tilde{x}_N(x(k))))
	\end{multline*}
	so by summing everything we get a telescopic sum that we can compute using the fact that the system is asymptotically stable so $\lim_{k\to\infty}\tilde{V}_N(x(k))=0$, we get :
	\begin{align*}
		\tilde{V}_N(x(0))&\geq\sum_{k=0}^\infty\tilde{l}(x(k),u(k))-\underbrace{\tilde{l}(\tilde{x}_N(x(k)), K\tilde{x}_N(x(k)))+\tilde{F}(\tilde{x}_N(x(k)))-\tilde{F}(f(\tilde{x}_N(x(k)),\tilde{x}_N(x(k))))}_{\eta(x(k))=O(\|x(0)\|^3)}\\
		&=\sum_{k=0}^\infty l(x(k), u(k))+\epsilon B_x(x(k))+\epsilon B_u(u(k))+\eta(x(k))\\
		&\geq x(0)^TP_{LQR}x(0)+\sum_{k=0}^\infty\eta(x(k))+\epsilon\sum_{k=0}^\infty B_x(x(k))+\epsilon\sum_{k=0}^\infty B_u(u(k))\\
	\end{align*}
	Note that even if we don't know a closed form for $\eta(x(k))$, we know that $\sum_{k=0}^\infty\eta(x(k))$ must be finite because it is bounded by $\tilde{V}_N(x(0))$\,.
	Now since the RRLB functions are all positive definite, we can easily conclude.
\end{proof}

We define for ease of notation the following quantities
\begin{align}
	\begin{split}
		\alpha(x(0))=\tilde{V}_N(x(0))-x(0)^TP_{LQR}x(0)-\sum_{k=0}^\infty\eta(x(k))
	\end{split}\\
	\begin{split}
		\beta_x=\underset{i,x}{\min}\{B_x(x)~|~\mathrm{row}_i(C_x)x=d_{x,i}\}
	\end{split}\\
	\begin{split}
		\beta_u=\underset{i,u}{\min}\{B_u(u)~|~\mathrm{row}_i(C_u)u=d_{u,i}\}
	\end{split}
\end{align}

Note that the bounds $\beta_x,\beta_u$ depend on the relaxation parameter $\delta$\,.

\begin{lemma}
	\label{thm:constraint-set-def-with-RRLB}
	For all relaxation parameter $\delta$:
	\begin{align*}
		\left\{x\in\R^{n_x}~|~B_x(x)\leq\beta_x\right\}\subseteq\cal{X}
		\left\{u\in\R^{n_u}~|~B_u(u)\leq\beta_u\right\}\subseteq\cal{U}
	\end{align*}
\end{lemma}

\begin{proof}
	See Lemma 1 in \cite{RRLB-linear-MPC}.
\end{proof}

\begin{theorem}
	In the same setting as lemma \ref{thm:RRLB-bounds-guarantees}, for any initial state $x(0)$ in the set
	$$\cal{X}_N(\delta):=\left\{x\in\R^{n_x}~|~\alpha(x(0))\leq\epsilon\min\left\{\beta_x,\beta_u\right\}\right\}$$
	there is no state or control constraint violation along the closed loop trajectories.
\end{theorem}

\begin{proof}
	For any $x(0)\in\cal{X}_N(\delta)$ it holds due to \ref{thm:RRLB-bounds-guarantees} that for all $k\geq 0,~\epsilon B_x(x(k))\leq\alpha(x(0))\leq\epsilon\beta_x$ so $B_x(x(k))\leq \beta_x$ and $x(k)\in\cal{X}$.
	The same reasoning applies on the controls.
\end{proof}

\section{Numerical extensions}\label{sec:numerical-extensions}

\subsection{Asymptotic stability of RTI scheme}\label{sec:RRLB-real-time-stability}
\subsection{Numerical experiments}\label{sec:RRLB-numerical-experiments}
\subsection{Influence of the number of SQP iterations}\label{sec:RRLB-SQP-iterations}

\newpage

\section{Appendix}
\printbibliography

\subsection*{Controllable vs. Stabilizable}\label{sec:controllability-stabilizability}

\subsection*{More on the DARE}\label{sec:DARE}

\begin{lemma}[Existence an Unicity of solution to the Lyapunov equation]
	
\end{lemma}

\begin{proof}
	
\end{proof}

\subsection*{Misc}

\begin{proof}[Proof of lemma \ref{thm:Lipchitzianity}]

\end{proof}

\end{document}