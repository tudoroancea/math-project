\documentclass[12pt]{article}
\usepackage[utf8]{inputenc} % pour le format de sortie
\usepackage[a4paper]{geometry}
\usepackage[T1]{fontenc}
\usepackage[english]{babel} % pour les accents
\usepackage{csquotes}
\usepackage{enumitem}
\usepackage{amssymb,amsmath,amsthm, amsfonts} % math libraries (amsthm : unumbered theorems)
\usepackage{mathtools} % for psmallmatrix
\usepackage{fancyhdr,multicol,accents, bbm,subcaption,caption,float,verbatim}
\usepackage[all]{xy} % for diagrams with arrows
\usepackage{tikz-cd} % for diagrams with arrows
\usepackage{graphicx} % to manage images
\usepackage{titlesec}
\usepackage{hyperref} % for hyperlinks to refs or bibliography
\usepackage{indentfirst} % for indenting the first line of a paragraph
\usepackage{optidef}
\usepackage[backend=bibtex]{biblatex} % for bibliography
\usepackage{bookmark}
\addbibresource{refs.bib}

% Margins, font size =====================================================================================================================
%\oddsidemargin = 0.5cm \evensidemargin = 0.5cm \textwidth = 6.3in
%\oddsidemargin = 1.2cm \evensidemargin = 1.2cm \textwidth = 6.3in
%\textheight =8.6in
\geometry{
	a4paper,
	total={170mm,257mm},
	left=20mm,
	top=20mm,
}

% Sections (theorems, propositions, lemmas…) =====================================================================================================================
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem*{conjecture}{\bf Conjecture}
\newtheorem{proposition}[theorem]{Proposition}
% \numberwithin{theorem}{section} % To display the section number in the theorem

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\newtheorem{exercise}{Exercise}
\newtheorem*{solution}{Solution}
\newtheorem*{answer}{Answer}
\newtheorem*{claim}{Claim}

\theoremstyle{remark}
\newtheorem*{theoremno}{{\bf Theorem}}
\newtheorem*{remark}{Remark}
\newtheorem*{example}{Example}
\newtheorem*{hint}{Hint}



% Commands =====================================================================================================================
\def\bb#1{\mathbb{#1}}
\def\cal#1{\mathcal{#1}}
\def\frak#1{\mathfrak{#1}}
\def\rm#1{\mathrm{#1}}
\def\bf#1{\mathbf{#1}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\K}{\mathbb{K}}
\newcommand{\bbP}{\mathbb{P}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\calP}{\mathcal{P}}
\newcommand{\G}{\mathcal{G}}
\newcommand{\calL}{\mathcal{L}}
\newcommand{\calC}{\mathcal{C}}
\newcommand{\calN}{\mathcal{N}}
\newcommand{\calF}{\mathcal{F}}
\newcommand{\calE}{\mathcal{E}}
\newcommand{\frakA}{\mathfrak{A}}
\newcommand{\frakS}{\mathfrak{S}}
\newcommand{\esp}{\mathbb{E}}
% \P = caracs spéciaux,\S = paragraphe, \L = L barre

% Existe déjà : ker, partie Im, Re, min, max, inf, sup, log, exp, sin, sinh, cos, cosh,, tan lim, liminf, limsup
\DeclareMathOperator{\Id}{Id}
\DeclareMathOperator{\Hom}{Hom}
\DeclareMathOperator{\Ima}{Im}
\DeclareMathOperator{\Homeo}{Homeo}
\DeclareMathOperator{\Aut}{Aut}
\DeclareMathOperator{\Bij}{Bij}
\DeclareMathOperator{\Isom}{Isom}
\DeclareMathOperator{\GL}{GL}
\DeclareMathOperator{\End}{End}
\DeclareMathOperator{\rang}{rang}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\vol}{vol}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\var}{Var}
\DeclareMathOperator{\erf}{erf}
\DeclareMathOperator{\spec}{spec}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\pgcd}{pgcd}
\DeclareMathOperator{\pgdc}{pgdc}

% Lois de probabilités
\DeclareMathOperator{\Geom}{Geom}
\DeclareMathOperator{\Bin}{Bin}
\DeclareMathOperator{\Exp}{Exp}
\DeclareMathOperator{\Ber}{Ber}
\DeclareMathOperator{\Student}{Student}
\DeclareMathOperator{\Poi}{Poi}
\newcommand{\czero}{\calC^0}
\newcommand{\cone}{\calC^1}
\newcommand{\ctwo}{\calC^2}
\newcommand{\cinf}{\calC^{\infty}}
\newcommand{\bigpeter}[1]{\Big\langle#1\Big\rangle}
\newcommand{\peter}[1]{\langle#1\rangle}
\newcommand{\transp}[1]{#1^t}
\newcommand{\series}[2]{\sum_{#1}^{\infty}#2}
\newcommand{\intt}[4]{\int_{#1}^{#2}#3\mathrm{d}#4}
\newcommand{\ddt}[1]{\frac{\mathrm{d}#1}{\mathrm{dt}}}
\newcommand{\deldt}[1]{\frac{\partial#1}{\partial\mathrm{t}}}
\newcommand{\rmd}[1]{\mathrm{d}#1}
\newcommand{\inv}[1]{#1^{-1}}
\newcommand{\dx}{\rmd x}
\newcommand{\dy}{\rmd y}
\newcommand{\dz}{\rmd z}
\newcommand{\dt}{\rmd t}
\newcommand{\du}{\rmd u}
\newcommand{\dv}{\rmd v}
\newcommand{\ds}{\rmd s}
\newcommand{\dxy}{\rmd xy}
\newcommand{\dyz}{\rmd yz}
\newcommand{\dyx}{\rmd yx}
\newcommand{\dzy}{\rmd zy}
\newcommand{\dzx}{\rmd zx}
\newcommand{\dxz}{\rmd xz}
\newcommand{\gtinf}[1]{\underset{#1\to\infty}{\longrightarrow}}
\newcommand{\sm}[4]{\begin{psmallmatrix}#1&#2\\#3&#4\end{psmallmatrix}}
\newcommand{\map}[4]{
	\begin{matrix}
		#1&\to&#2\\#3&\mapsto&#4
	\end{matrix}
}


\title{Stability properties of Relaxed Recentered Log-Barrier function based Nonlinear MPC}
\author{Tudor Oancea}
\date{March 2022}

\begin{document}
\maketitle

\section{Introduction}
Given a controlled nonlinear dynamical system of the form $x^+=f(x,u)$ with state and control constraints $x\in\cal{X}\subseteq\R^{n_x},~u\in\cal{U}\subseteq\R^{n_u}$ and a fixed point $x^*$ for these dynamics, i.e. a point such that $f(x^*,0)=x^*$, the problem of \textit{stabilization} is to find a a feedback control law $\mu:\cal{X}\to\cal{U}$ such that $x^*$ is asymptoticall stable for the dynamical system $x^+=f(x,\mu(x))$.
Such a problem is usually tackled using \textit{optimal control}, and precisely \textit{model predictive control} (MPC), an algorithm that defines this feedback control as the solution to an optimization problem of the following form :
\begin{align}
	\begin{split}
		\label{NMPC}
		V_N(x)=\underset{\mathbf{x},\mathbf{u}}{\min} &\quad J_N(\mathbf{x},\mathbf{u})\\
		\text{s.t.} &\quad x_0=x\text{ and }x_{k+1}=f(x_k,u_k),~k=0,\dots,N-1\\
		&\quad x_k\in\cal{X},~k=0,\dots,N\\
		&\quad u_k\in\cal{U},~k=0,\dots,N-1
	\end{split}
\end{align}
Here $N$ is called the horizon size, $J_N$ is the cost function that is usually described with \textit{stage costs} $l:\cal{X}\times\cal{U}\to\R$ and \textit{final cost} $F:\cal{X}\to\R$ by 
$$J_N(\mathbf{x},\mathbf{u})=\sum_{k=0}^{N-1}l(x_k,u_k)~+~F(x_N)$$
The system is then controlled by applying the first value of the optimal control sequence to the system.\newline
In our work the follwoing assumptions will be made :
\begin{assumption}~
	\begin{itemize}[label=\textbullet]
		\item The function $f$ describing the dynamics is a general $C^2$ function, not necessarily linear.
		\item Without loss of generality, $x^*=0$. We can always come back to this case by defining new translated states $\tilde{x}:=x-x^*$ and new dynamics and new constraints accordingly by translation.
		\item $x^*=0\in\mathrm{int}\,\cal{X}$ and $0\in\mathrm{int}\,\cal{U}$
		\item The stage costs and the final costs are quadratic : $l(x,u)=x^TQx+u^TQu,~F(x)=x^TPx$ with $Q,R$ and $P$ positive definite matrices.
		This is very usual in MPC.
		\item The state and constraints sets are polytopic :
		\begin{align*}
			X=\left\{x\in\R^{n_x}~|~C_xx\leq d_x\text{ with }C_x\in\R^{q_x\times n_x}\text{ and }d_x\in\R^{q_x}\right\}\\
			U=\left\{u\in\R^{n_u}~|~C_uu\leq d_u\text{ with }C_u\in\R^{q_u\times n_u}\text{ and }d_u\in\R^{q_u}\right\}
		\end{align*}
		Up to defining additional states and/or controls and modifying the dynamics accordingly, this can always be achieved.
	\end{itemize}
\end{assumption}
The goal is usually to define the terminal cost $F(x)$ in such a way that the optimal value function $V_N$ is a \textit{Lyapunov function}, which would prove that $x^*=0$ is asymptotically stable for the system controlled by the MPC.
In some cases the authors also include \textit{terminal constraints} on the last state $x_N$ to ensure this stability, but here we are solely focusing on MPC with terminal costs and without terminal constraints.
\newline
Our work presents a new formulation that is based on this classical MPC framework and replaces the inequality constraints in the optimization problem (given by the state and control constraints) by some modified log-barrier functions added to the objective function.
To properly introduce this new formulation let's introduce the central notion of \textit{relaxed recentered log-barrier function}.

\section{Statement of the new formulation}
\begin{definition}
	Given a constraint of the form $c^Tx\leq d$, the associated \textit{log-barrier function} is defined as $-\log(d-c^Tx)$.
	Such a function is defined on the interior of feasible set of the constraint and becomes infinity near its boundary.
	For a set of polytopic constraints similar to the ones describes above, we can define the log-barrier for the state constraints as the sum of the log-barriers for each constraint :
	$$B_x(x)=\sum_{i=1}^{q_x}-\log(d_{x,i}-\mathrm{row}_i(C_x)x)$$

\end{definition}
\begin{definition}
	A \textit{weight recentered log-barrier function} for a set of polytopic constraints similar to the ones described above is of the form :
	$$B_x(x)=\sum_{i=1}^{q_x}(1+w_{x,i})\left[\log(d_{x,i})-\log(d_{x,i}-\mathrm{row}_i(C_x)x)\right]$$
	where the weights $w_{x,i}$ are defined as chosen such that $B_x(0)=0$ and $\nabla B_x(0)=0$.
\end{definition}
\begin{definition}
	A \textit{relaxed recentered log-barrier function} (RRLB function) is defined by :
	\begin{align*}
		B_x(x)&=\sum_{i=1}^{q_x}(1+w_{x,i})B_{x,i}(x)\\
		\text{ with }B_{x,i}(x)&=\begin{cases}
			\log(d_{x,1})-\log(d_{x,1}-\mathrm{row}_i(C_x)x)&\text{if }d_{x,i}-\mathrm{row}_i(C_x)x>\delta\\
			\beta(d_{x,1}-\mathrm{row}_i(C_x)x;\delta)&\text{ otherwise}
		\end{cases}
	\end{align*}
	where $0<\delta$ is a relaxation parameter and $\beta$ is a function that twice continuously extends the log-barrier function on $(-\infty,\delta]$.
	The simplest example of such a function is 
	$$\beta(z;\delta)=\frac{1}{2}\left[ \left( \frac{z-2\delta}{\delta} \right)^2-1 \right]-\log(\delta)$$
\end{definition}

\begin{lemma}
	\label{RRLB-quadratic-bound}
	The RRLB functions are upper bounded by quadratic functions.
\end{lemma}
\begin{proof}
	The proof is similar to the one of the Lemma 3 of %\cite{RRLB-linear-MPC}.
\end{proof}

\newpage
Now we can finally define our new MPC formulation as follows :
\begin{align}
	\begin{split}\label{RRLB-NMPC}
		\tilde{V}_N(x)=\underset{\mathbf{x},\mathbf{u}}{\min} &\quad \tilde{J}_N(\mathbf{x},\mathbf{u})\\
		\text{s.t.} &\quad x_0=x\text{ and }x_{k+1}=f(x_k,u_k),~k=0,\dots,N-1\\
	\end{split}
\end{align}
where the new objective function $\tilde{J}_N(\mathbf{x},\mathbf{u})=\sum_{k=0}^{N-1}\tilde{l}(x_k,u_k)~+~\tilde{F}(x_N)$ is defined using the new stage costs $\tilde{l}(x,u)=l(x,u)+\epsilon B_x(x)+\epsilon B_u(u)$ and the new terminal cost $\tilde{F}(x)=x^TPx$ for a certain matrix $P$ that will be determined later.
The barrier parameter $\epsilon$ has in theory the following interpretation : when it goes to zero, the solution of problem \ref{RRLB-NMPC} converges to the one of \ref{NMPC}.


\section{Theoretical properties of RRLB Nonlinear MPC}

\subsection{Nominal asymptotic stability}

\begin{lemma}
	\label{Lipchitzianity}
	Consider the problem \ref{RRLB-NMPC} and re-write it in a simpler way as 
	$$\tilde{V}_N(x)=\underset{\mathbf{u}}{\min} \quad J(x,\mathbf{u})$$
	where $J(x,\mathbf{u})=\tilde{l}(x_0,u_0)+\tilde{l}(f(x_0,u_0),u_1)+\dots+\tilde{F}(f(f(...),u_{N-1}))$\,.
	If for a certain value for the initial state $x$ we denote by $\tilde{\mathbf{u}}(x)=(\tilde{u}_0(x),\dots,\tilde{u}_{N-1}(x))$ the optimal sequence of controls and we suppose that $D_\mathbf{u}J(x,\tilde{\mathbf{u}})=0$ and $\nabla_{\mathbf{u}\mathbf{u}}^2J(x, \tilde{\mathbf{u}})\succ 0$ (the matrix is positive definite) then :
	\begin{itemize}[label=\textbullet]
		\item $\forall k=0,\dots,N-1,\quad \|\tilde{u}_k(x)\|=O(\|x\|)$
		\item $\forall k=1,\dots,N,\quad \|\tilde{x}_k(x)\|=f(f(\dots,u_{k-2}),u_{k-1})=O(\|x\|)$
	\end{itemize}
\end{lemma}
\begin{proof}
	See appendix
\end{proof}

Now the main piece :

\begin{theorem}\label{nominal-stability}
	Let's consider the problem \ref{RRLB-NMPC} and assume the following :
	\begin{enumerate}
		\item the assumptions of previous lemma
		\item When linearizing the system dynamics around the equilibrium and letting $A=D_xf(0,0),~B=D_uf(0,0)$, we suppose that the pair $(A,B)$ is stabilizable.
		This implies in particular that there exists a stabilizing cost $K$, i.e. a matrix such that $A_K:=A+BK$ only has eigenvalues in the unit disk.
		\item The matrix $P$ defining the terminal costs is the unique positive definite solution to the following Lyapunov equation :
		\begin{equation*}
			P=A_K^TPA_K+\mu Q_K
		\end{equation*}
		where $\mu>1$ and $Q_K=Q+\epsilon M_x+K^T(R+\epsilon M_u)K$\,.
	\end{enumerate}	
	Then if we use the same notations for the optimal controls and states as in the previous lemma, the origin is asymptotically stable for the dynamical system $x^+=f(x,\tilde{u}_0(x))$ for all initial state in a certain neighborhood of the origin.
\end{theorem}

\begin{remark}
	\begin{enumerate}
		\item The matrix $K$ can be constructed using the Discrete Algebraic Riccati Equation for the infinite horizon LQR problem :
		\begin{align}
			\begin{split}\label{inf-LQR}
				\underset{\mathbf{x},\mathbf{u}}{\min} &\quad \sum_{k=0}^\infty x_k^T(Q+\epsilon M_x)x_k+u_k^T(R+\epsilon M_u)u_k\\
				\text{s.t.} &\quad x_{k+1}=Ax_k+Bu_k,~k=0,\dots,N-1\\
			\end{split}
		\end{align}
	\end{enumerate}
\end{remark}

\begin{proof}~
	By writing the Taylor expansion of the stage costs $\tilde{l}$ we can see that
	\begin{align*}
		\tilde{l}(x,u)&=x^T[\nabla_{xx}^2\tilde{l}(0,0)] x+u^T[\nabla_{uu}^2\tilde{l}(0,0)]u+O(\|x\|^3+\|u\|^3)\\
		&=x^T[Q+\epsilon M_x]x+u^T[R+\epsilon M_u]u+O(\|x\|^3+\|u\|^3)
	\end{align*}
	so $\tilde{l}(x,Kx)=x^TQ_Kx+O(\|x\|^3)$\,.
	By the second assumption, we also have $\forall x\in\R^{n_x}$:
	$$\tilde{F}(A_Kx)+\mu x^T Q_K x-\tilde{F}(x)=0$$
	We can use the same reasoning as in the paragraph 2.5.5 of \cite[MPC Theory, Computation and Design]{MPC-book} to show that $\tilde{F}$ is a local Lyapunov funnction, i.e. there exists a neighborhood of the origin such that $\forall x$ in it :
	\begin{align*}
		\tilde{F}(f(x,Kx))+x^T Q_K x-\tilde{F}(x)&\leq 0\\
		\Longleftrightarrow\tilde{F}(f(x,Kx))-\tilde{F}(x)+\tilde{l}(x,Kx)&= O(\|x\|^3)
	\end{align*}

	What's more, by previous lemma, the predicted states are all Lipschitz with respect to the initial state, so we can choose an even smaller neighborhood such that $\tilde{x}_N(x)$ is also in it.
	
	Now using the optimal sequence of states and controls of the problem \ref{RRLB-NMPC} starting at $x$, we can construct new feasible sequences for the problem starting at $\tilde{x}_1(x)$ as 
	$\mathbf{x}'=(\tilde{x}_1,\dots,\tilde{x}_N,f(\tilde{x}_N,K\tilde{x}_N))$ and $\mathbf{u}'=(\tilde{u}_1,\dots,\tilde{u}_{N-1},K\tilde{x}_N)$ \,.
	Then we have :
	$$\tilde{V}_N(\tilde{x}_1)\leq\tilde{J}_N(\mathbf{x}',\mathbf{u}')=\underbrace{\tilde{J}_N(\tilde{\mathbf{x}},\tilde{\mathbf{u}})}_{=\tilde{V}_N(x)}~\underbrace{\underbrace{-\tilde{l}(x,\tilde{u}_0)}_{=O(\|x\|^2)}+\underbrace{\tilde{F}(f(\tilde{x}_N,K\tilde{x}_N))-\tilde{F}(\tilde{x}_N)+\tilde{l}(\tilde{x}_N,K\tilde{x}_N) }_{=O(\|\tilde{x}_N\|^3)=O(\|x\|^3)} }_{\leq-c\|x\|^2\text{ in a smaller nbh }}\checkmark$$
	
	It is easy to show that $\tilde{V}_N$ is lower and upper bounded by coercive quadratic functions (see appendix), so that $\tilde{V}_N$ is a Lyapunov function in a small neighborhood around the origin.~\checkmark
\end{proof}

\subsection{Constraints violation guarantees}
This section follows closely the section IV.D of \cite{RRLB-linear-MPC} but gives more loose results that cannot take us as far.
In particular, will show that we can ensure the existence of a neighborhood around the origin such that if we start in it, the states and controls along the closed-loop simulation will never violate the constraints.
However, this neighborhood cannot be easily computed because of the generality of the considered dynamics.

% \begin{definition}
% 	For our RRLB functions $B_x$ and $B_u$ we can define :
% \end{definition}

\begin{lemma}
	\label{RRLB-bounds-guarantees}
	Consider problem \ref{RRLB-NMPC} and an initial state $x(0)$ in the neighborhood given by \ref{nominal-stability}.
	Let's denote by $\left\{x(0),x(1),\dots\right\}$ and $\left\{u(0), u(1),\dots\right\}$ the closed-loop state and control trajectories (given by $u(k)=\tilde{u}_0(x(k)),~x(k+1)=f(x(k),u(k))$).
	Then $\forall k\geq 0$:
	\begin{align*}
		B_x(x(k))&\leq\frac{1}{\epsilon}\left(\tilde{V}_N(x(0))-x(0)^TP_{LQR}x(0)-\sum_{k=0}^\infty\eta(x(k))\right)\\
		B_u(u(k))&\leq\frac{1}{\epsilon}\left(\tilde{V}_N(x(0))-x(0)^TP_{LQR}x(0)-\sum_{k=0}^\infty\eta(x(k))\right)
	\end{align*}
	where $P_{LQR}$ is the solution to the DARE associated \ref{inf-LQR} and $\eta(x)=\tilde{l}(\tilde{x}_N(x),K\tilde{x}_N(x))+\tilde{F}(\tilde{x}_N(x))-\tilde{F}(f(\tilde{x}_N(x), K\tilde{x}_N(x)))$.
\end{lemma}

\begin{proof}
	In the proof of theorem \ref{nominal-stability} we showed that $\forall k\geq 0$:
	\begin{multline*}
		\tilde{V}_N(x(k+1))-\tilde{V}_N(x(k))\leq-\tilde{l}(x(k),u(k))+\tilde{l}(\tilde{x}_N(x(k)), K\tilde{x}_N(x(k)))\\
		-\tilde{F}(\tilde{x}_N(x(k)))+\tilde{F}(f(\tilde{x}_N(x(k)),\tilde{x}_N(x(k))))
	\end{multline*}
	so by summing everything we get a telescopic sum that we can compute using the fact that the system is asymptotically stable so $\lim_{k\to\infty}\tilde{V}_N(x(k))=0$, we get :
	\begin{align*}
		\tilde{V}_N(x(0))&\geq\sum_{k=0}^\infty\tilde{l}(x(k),u(k))-\underbrace{\tilde{l}(\tilde{x}_N(x(k)), K\tilde{x}_N(x(k)))+\tilde{F}(\tilde{x}_N(x(k)))-\tilde{F}(f(\tilde{x}_N(x(k)),\tilde{x}_N(x(k))))}_{\eta(x(k))=O(\|x(0)\|^3)}\\
		&=\sum_{k=0}^\infty l(x(k), u(k))+\epsilon B_x(x(k))+\epsilon B_u(u(k))+\eta(x(k))\\
		&\geq x(0)^TP_{LQR}x(0)+\sum_{k=0}^\infty\eta(x(k))+\epsilon\sum_{k=0}^\infty B_x(x(k))+\epsilon\sum_{k=0}^\infty B_u(u(k))\\
	\end{align*}
	Note that even if we don't know a closed form for $\eta(x(k))$, we know that $\sum_{k=0}^\infty\eta(x(k))$ must be finite because it is bounded by $\tilde{V}_N(x(0))$\,.
	Now since the RRLB functions are all positive definite, we can easily conclude.
\end{proof}

We define for ease of notation the following quantities
\begin{align}
	\begin{split}\label{bruh}
		\alpha(x(0))=\tilde{V}_N(x(0))-x(0)^TP_{LQR}x(0)-\sum_{k=0}^\infty\eta(x(k))
	\end{split}\\
	\begin{split}\label{bruh2}
		\beta_x=\underset{i,x}{\min}\{B_x(x)~|~\mathrm{row}_i(C_x)x=d_{x,i}\}
	\end{split}\\
	\begin{split}\label{bruh3}
		\beta_u=\underset{i,u}{\min}\{B_u(u)~|~\mathrm{row}_i(C_u)u=d_{u,i}\}
	\end{split}
\end{align}

Note that the bounds $\beta_x,\beta_u$ depend on the relaxation parameter $\delta$\,.

\begin{lemma}
	\label{constraint-set-def-with-RRLB}
	For all relaxation parameter $\delta$:
	\begin{align*}
		\left\{x\in\R^{n_x}~|~B_x(x)\leq\beta_x\right\}\subseteq\cal{X}
		\left\{u\in\R^{n_u}~|~B_u(u)\leq\beta_u\right\}\subseteq\cal{U}
	\end{align*}
\end{lemma}

\begin{proof}
	See Lemma 1 in \cite{RRLB-linear-MPC}.
\end{proof}

\begin{theorem}
	In the same setting as lemma \ref{RRLB-bounds-guarantees}, for any initial state $x(0)$ in the set
	$$\cal{X}_N(\delta):=\left\{x\in\R^{n_x}~|~\alpha(x(0))\leq\epsilon\min\left\{\beta_x,\beta_u\right\}\right\}$$
	there is no state or control constraint violation along the closed loop trajectories.
\end{theorem}

\begin{proof}
	For any $x(0)\in\cal{X}_N(\delta)$ it holds due to \ref{RRLB-bounds-guarantees} that for all $k\geq 0,~\epsilon B_x(x(k))\leq\alpha(x(0))\leq\epsilon\beta_x$ so $B_x(x(k))\leq \beta_x$ and $x(k)\in\cal{X}$.
	The same reasoning applies on the controls.
\end{proof}

\section{Numerical extensions}

\subsection{Real Time Iteration methods}
\subsubsection{Asymptotic stability of RTI scheme}
\subsubsection{Numerical experiments}

\subsection{Parallelization}
\subsubsection{Numerical experiments}

\section{Appendix}
\printbibliography
\begin{proof}[Proof of lemma \ref{Lipchitzianity}]
\cite{RRLB-linear-MPC}
\end{proof}

\begin{lemma}[Existence an Unicity of solution to the Lyapunov equation]
	
\end{lemma}

\begin{proof}
	
\end{proof}

\begin{lemma}[Coercive quadratic lower and upper bounds for objective value function]

\end{lemma}

\end{document}