\documentclass[12pt]{article}
\usepackage[utf8]{inputenc} % pour le format de sortie
\usepackage[a4paper]{geometry}
\usepackage[T1]{fontenc}
\usepackage[english]{babel} % pour les accents
\usepackage{csquotes}
\usepackage{enumitem}
\usepackage{amssymb,amsmath,amsthm, amsfonts} % math libraries (amsthm : unumbered theorems)
\usepackage{mathtools} % for psmallmatrix
\usepackage{fancyhdr,multicol,accents, bbm,subcaption,caption,float,verbatim}
\usepackage[all]{xy} % for diagrams with arrows
\usepackage{tikz-cd} % for diagrams with arrows
\usepackage{graphicx} % to manage images
\usepackage{titlesec}
\usepackage{hyperref} % for hyperlinks to refs or bibliography
\usepackage{indentfirst} % for indenting the first line of a paragraph
\usepackage{optidef}
\usepackage{biblatex} % for bibliography
\addbibresource{refs.bib}

% Margins, font size =====================================================================================================================
%\oddsidemargin = 0.5cm \evensidemargin = 0.5cm \textwidth = 6.3in
%\oddsidemargin = 1.2cm \evensidemargin = 1.2cm \textwidth = 6.3in
%\textheight =8.6in
\geometry{
	a4paper,
	total={170mm,257mm},
	left=20mm,
	top=20mm,
}

% Sections (theorems, propositions, lemmas…) =====================================================================================================================
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem*{conjecture}{\bf Conjecture}
\newtheorem{proposition}[theorem]{Proposition}
% \numberwithin{theorem}{section} % To display the section number in the theorem

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\newtheorem{exercise}{Exercise}
\newtheorem*{solution}{Solution}
\newtheorem*{answer}{Answer}
\newtheorem*{claim}{Claim}

\theoremstyle{remark}
\newtheorem*{theoremno}{{\bf Theorem}}
\newtheorem*{remark}{Remark}
\newtheorem*{example}{Example}
\newtheorem*{hint}{Hint}



% Commands =====================================================================================================================
\def\bb#1{\mathbb{#1}}
\def\cal#1{\mathcal{#1}}
\def\frak#1{\mathfrak{#1}}
\def\rm#1{\mathrm{#1}}
\def\bf#1{\mathbf{#1}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\K}{\mathbb{K}}
\newcommand{\bbP}{\mathbb{P}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\calP}{\mathcal{P}}
\newcommand{\G}{\mathcal{G}}
\newcommand{\calL}{\mathcal{L}}
\newcommand{\calC}{\mathcal{C}}
\newcommand{\calN}{\mathcal{N}}
\newcommand{\calF}{\mathcal{F}}
\newcommand{\calE}{\mathcal{E}}
\newcommand{\frakA}{\mathfrak{A}}
\newcommand{\frakS}{\mathfrak{S}}
\newcommand{\esp}{\mathbb{E}}
% \P = caracs spéciaux,\S = paragraphe, \L = L barre

% Existe déjà : ker, partie Im, Re, min, max, inf, sup, log, exp, sin, sinh, cos, cosh,, tan lim, liminf, limsup
\DeclareMathOperator{\Id}{Id}
\DeclareMathOperator{\Hom}{Hom}
\DeclareMathOperator{\Ima}{Im}
\DeclareMathOperator{\Homeo}{Homeo}
\DeclareMathOperator{\Aut}{Aut}
\DeclareMathOperator{\Bij}{Bij}
\DeclareMathOperator{\Isom}{Isom}
\DeclareMathOperator{\GL}{GL}
\DeclareMathOperator{\End}{End}
\DeclareMathOperator{\rang}{rang}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\vol}{vol}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\var}{Var}
\DeclareMathOperator{\erf}{erf}
\DeclareMathOperator{\spec}{spec}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\pgcd}{pgcd}
\DeclareMathOperator{\pgdc}{pgdc}

% Lois de probabilités
\DeclareMathOperator{\Geom}{Geom}
\DeclareMathOperator{\Bin}{Bin}
\DeclareMathOperator{\Exp}{Exp}
\DeclareMathOperator{\Ber}{Ber}
\DeclareMathOperator{\Student}{Student}
\DeclareMathOperator{\Poi}{Poi}
\newcommand{\czero}{\calC^0}
\newcommand{\cone}{\calC^1}
\newcommand{\ctwo}{\calC^2}
\newcommand{\cinf}{\calC^{\infty}}
\newcommand{\bigpeter}[1]{\Big\langle#1\Big\rangle}
\newcommand{\peter}[1]{\langle#1\rangle}
\newcommand{\transp}[1]{#1^t}
\newcommand{\series}[2]{\sum_{#1}^{\infty}#2}
\newcommand{\intt}[4]{\int_{#1}^{#2}#3\mathrm{d}#4}
\newcommand{\ddt}[1]{\frac{\mathrm{d}#1}{\mathrm{dt}}}
\newcommand{\deldt}[1]{\frac{\partial#1}{\partial\mathrm{t}}}
\newcommand{\rmd}[1]{\mathrm{d}#1}
\newcommand{\inv}[1]{#1^{-1}}
\newcommand{\dx}{\rmd x}
\newcommand{\dy}{\rmd y}
\newcommand{\dz}{\rmd z}
\newcommand{\dt}{\rmd t}
\newcommand{\du}{\rmd u}
\newcommand{\dv}{\rmd v}
\newcommand{\ds}{\rmd s}
\newcommand{\dxy}{\rmd xy}
\newcommand{\dyz}{\rmd yz}
\newcommand{\dyx}{\rmd yx}
\newcommand{\dzy}{\rmd zy}
\newcommand{\dzx}{\rmd zx}
\newcommand{\dxz}{\rmd xz}
\newcommand{\gtinf}[1]{\underset{#1\to\infty}{\longrightarrow}}
\newcommand{\sm}[4]{\begin{psmallmatrix}#1&#2\\#3&#4\end{psmallmatrix}}
\newcommand{\map}[4]{
	\begin{matrix}
		#1&\to&#2\\#3&\mapsto&#4
	\end{matrix}
}


\title{Stability properties of Relaxed Recentered log-barrier function based Nonlinear MPC}
\author{Tudor Oancea}
\date{March 2022}

\begin{document}
\maketitle

\section{Introduction}
Given a controlled nonlinear dynamical system of the form $x^+=f(x,u)$ with state and control constraints $x\in\cal{X}\subseteq\R^{n_x},~u\in\cal{U}\subseteq\R^{n_u}$ and a fixed point $x^*$ for these dynamics, i.e. a point such that $f(x^*,0)=x^*$, the problem of \textit{stabilization} is to find a a feedback control law $\mu:\cal{X}\to\cal{U}$ such that $x^*$ is asymptoticall stable for the dynamical system $x^+=f(x,\mu(x))$.
Such a problem is usually tackled using \textit{optimal control}, and precisely \textit{model predictive control} (MPC), an algorithm that defines this feedback control as the solution to an optimization problem of the following form :
\begin{align}
	\begin{split}
		\label{NMPC}
		V_N(x)=\underset{\mathbf{x},\mathbf{u}}{\min} &\quad J_N(\mathbf{x},\mathbf{u})\\
		\text{s.t.} &\quad x_0=x\text{ and }x_{k+1}=f(x_k,u_k),~k=0,\dots,N-1\\
		&\quad x_k\in\cal{X},~k=0,\dots,N\\
		&\quad u_k\in\cal{U},~k=0,\dots,N-1
	\end{split}
\end{align}
Here $N$ is called the horizon size, $J_N$ is the cost function that is usually described with \textit{stage costs} $l:\cal{X}\times\cal{U}\to\R$ and \textit{final cost} $F:\cal{X}\to\R$ by 
$$J_N(\mathbf{x},\mathbf{u})=\sum_{k=0}^{N-1}l(x_k,u_k)~+~F(x_N)$$
The system is then controlled by applying the first value of the optimal control sequence to the system.\newline
In our work the follwoing assumptions will be made :
\begin{assumption}~
	\begin{itemize}[label=\textbullet]
		\item The function $f$ describing the dynamics is a general $C^2$ function, not necessarily linear.
		\item Without loss of generality, $x^*=0$. We can always come back to this case by defining new translated states $\tilde{x}:=x-x^*$ and new dynamics and new constraints accordingly by translation.
		\item $x^*=0\in\mathrm{int}\,\cal{X}$ and $0\in\mathrm{int}\,\cal{U}$
		\item The stage costs and the final costs are quadratic : $l(x,u)=x^TQx+u^TQu,~F(x)=x^TPx$ with $Q,R$ and $P$ positive definite matrices.
		This is very usual in MPC.
		\item The state and constraints sets are polytopic :
		\begin{align*}
			X=\left\{x\in\R^{n_x}~|~C_xx\leq d_x\text{ with }C_x\in\R^{q_x\times n_x}\text{ and }d_x\in\R^{q_x}\right\}\\
			U=\left\{u\in\R^{n_u}~|~C_uu\leq d_u\text{ with }C_u\in\R^{q_u\times n_u}\text{ and }d_u\in\R^{q_u}\right\}
		\end{align*}
		Up to defining additional states and/or controls and modifying the dynamics accordingly, this can always be achieved.
	\end{itemize}
\end{assumption}
The goal is usually to define the terminal cost $F(x)$ in such a way that the optimal value function $V_N$ is a \textit{Lyapunov function}, which would prove that $x^*=0$ is asymptotically stable for the system controlled by the MPC.
In some cases the authors also include \textit{terminal constraints} on the last state $x_N$ to ensure this stability, but here we are solely focusing on MPC with terminal costs and without terminal constraints.
\newline
Our work presents a new formulation that is based on this classical MPC framework and replaces the inequality constraints in the optimization problem (given by the state and control constraints) by some modified log-barrier functions added to the objective function.
To properly introduce this new formulation let's introduce the central notion of \textit{relaxed recentered log-barrier function}.

\section{Statement of the new formulation}
\begin{definition}
	Given a constraint of the form $c^Tx\leq d$, the associated \textit{log-barrier function} is defined as $-\log(d-c^Tx)$.
	Such a function is defined on the interior of feasible set of the constraint and becomes infinity near its boundary.
	For a set of polytopic constraints similar to the ones describes above, we can define the log-barrier for the state constraints as the sum of the log-barriers for each constraint :
	$$B_x(x)=\sum_{i=1}^{q_x}-\log(d_{x,i}-\mathrm{row}_i(C_x)x)$$

\end{definition}
\begin{definition}
	A \textit{weight recentered log-barrier function} for a set of polytopic constraints similar to the ones described above is of the form :
	$$B_x(x)=\sum_{i=1}^{q_x}(1+w_{x,i})\left[\log(d_{x,i})-\log(d_{x,i}-\mathrm{row}_i(C_x)x)\right]$$
	where the weights $w_{x,i}$ are defined as chosen such that $B_x(0)=0$ and $\nabla B_x(0)=0$.
\end{definition}
\begin{definition}
	A \textit{relaxed recentered log-barrier function} (RRLB function) is defined by :
	\begin{align*}
		B_x(x)&=\sum_{i=1}^{q_x}(1+w_{x,i})B_{x,i}(x)\\
		\text{ with }B_{x,i}(x)&=\begin{cases}
			\log(d_{x,1})-\log(d_{x,1}-\mathrm{row}_i(C_x)x)&\text{if }d_{x,i}-\mathrm{row}_i(C_x)x>\delta\\
			\beta(d_{x,1}-\mathrm{row}_i(C_x)x;\delta)&\text{ otherwise}
		\end{cases}
	\end{align*}
	where $0<\delta$ is a relaxation parameter and $\beta$ is a function that twice continuously extends the log-barrier function on $(-\infty,\delta]$.
	The simplest example of such a function is 
	$$\beta(z;\delta)=\frac{1}{2}\left[ \left( \frac{z-2\delta}{\delta} \right)^2-1 \right]-\log(\delta)$$
\end{definition}

\begin{lemma}
	\label{RRLB-quadratic-bound}
	The RRLB functions are upper bounded by quadratic functions.
\end{lemma}
\begin{proof}
	The proof is similar to the one of the Lemma 3 of \cite{RRLB-linear-MPC}.
\end{proof}

\newpage
Now we can finally define our new MPC formulation as follows :
\begin{align}
	\begin{split}\label{RRLB-NMPC}
		\tilde{V}_N(x)=\underset{\mathbf{x},\mathbf{u}}{\min} &\quad \tilde{J}_N(\mathbf{x},\mathbf{u})\\
		\text{s.t.} &\quad x_0=x\text{ and }x_{k+1}=f(x_k,u_k),~k=0,\dots,N-1\\
	\end{split}
\end{align}
where the new objective function $\tilde{J}_N(\mathbf{x},\mathbf{u})=\sum_{k=0}^{N-1}\tilde{l}(x_k,u_k)~+~\tilde{F}(x_N)$ is defined using the new stage costs $\tilde{l}(x,u)=l(x,u)+\epsilon B_x(x)+\epsilon B_u(u)$ and the new terminal cost $\tilde{F}(x)=x^TPx$.
The barrier parameter $\epsilon$ has in theory the following interpretation : when it goes to zero, the solution of problem \ref{RRLB-NMPC} converges to the one of \ref{NMPC}.
The matrix $P$ is chosen as the unique solution to the modified Riccati equation 
\begin{equation}
	\label{Riccati}
	P=A^TPA-A^TPB\inv{(R+\epsilon M_u+B^TPB)}B^TPA+Q+\epsilon M_x
\end{equation}

\section{Stability property of RRLB Nonlinear MPC}
We are going to show the following stability result :
\begin{theorem}
	Let's denote by $\tilde{\mathbf{u}}(x)=(\tilde{u}_0(x),\dots,\tilde{u}_{N-1}(x))$ and $\tilde{\mathbf{x}}(x)=(\tilde{x}_0(x)=x,\tilde{x}_1(x),\dots,\tilde{x}_N(x))$ the sequences of optimal controls and states given by \ref{RRLB-NMPC}.
	Then the origin is asymptotically stable for the dynamical system $x^+=f(x,\tilde{u}_0(x))$ for all initial state in a neighborhood of the origin.
\end{theorem}

\begin{proof}~
	\begin{itemize}[label=\textbullet]
		\item \underline{Step 1 : show that $\tilde{V}_\infty(x)=F(x)+O(\|x\|^3)$} \newline 
		where $\tilde{V}_\infty$ is the infinite horizon version of \ref{RRLB-NMPC} defined by :
		\begin{align*}
			\tilde{V}_\infty(x)=\underset{\mathbf{x},\mathbf{u}}{\min} &\quad\sum_{k=0}^\infty\tilde{l}(x_k,u_k)\\
			\text{s.t.} &\quad x_0=x\text{ and }x_{k+1}=f(x_k,u_k),~k\geq 0\\
		\end{align*}
		By \textbf{???} we know that $\tilde{V}_\infty\in\ctwo$ and we can write its Taylor expansion :
		$$\tilde{V}_\infty(x)=\tilde{V}_\infty(0)+\nabla\tilde{V}_\infty(0)^Tx+x^T\left( \underbrace{\frac{1}{2}\nabla^2\tilde{V}_\infty(0)}_{=:\tilde{P}}\right)x+O(\|x\|^3)$$
		It is easy to see that $\tilde{V}_\infty(0)=0$ and $\nabla\tilde{V}_\infty(0)$, so if show that $\tilde{P}=P$ then we will have shown that $\tilde{V}_\infty(x)=F(x)+O(\|x\|^3)$\,.

		By the dynamic programming principle we have:
		\begin{equation}\label{RRLB-NMPC-inf-DP}
			\tilde{V}_\infty(x)=\underset{u_0}{\mathrm{\min}}\quad\tilde{l}(x,u_0)+\tilde{V}_\infty(f(x,u_0))
		\end{equation}
		Let $u_0^*(x)$ be the minimizer of \ref{RRLB-NMPC-inf-DP}, which we are going to denote as $u^*$ for simplicity.
		By \textbf{???} we know that $u^*=O(\|x\|)$.
		In our case we can show exactly that the minimizer is a stationnary point so :
		\begin{align*}
			0&=\nabla_u\tilde{l}(x;u^*)+\nabla_u f(x,u^*)\nabla\tilde{V}_\infty(f(x,u^*))\\
			&=R^*+\epsilon\nabla B_u(u^*)+\nabla_u f(x,u^*)\nabla\tilde{V}_\infty(f(x,u^*))\\
			&=Ru^*+\epsilon\left(\underbrace{\nabla B_u(0)}_{=0}+\nabla^2B_u(0)u^*+O(\|u^*\|^2)\right)\\
			&+(B^T+O(\|u^*\|^2))\left(\tilde{P}(Ax+Bu^*+O(\|x\|^2+\|u^*\|^2))+O\left(\left\|Ax+Bu^*+O(\|x\|^2+\|u^*\|^2)\right\|^2\right)\right)\\
			&=R^*+\epsilon M_uu^*+B^T\tilde{P}(Ax+Bu^*)+O(\|x\|^2)
		\end{align*}
		where we use that
		\begin{align*}
			&f(x,u)+Ax+Bu+O(\|x\|^2+\|u\|^2)\Longrightarrow\nabla_u f(x,u)=B^T+O(\|u\|)\\
			&\tilde{V}_\infty(x)=x^T\tilde{P}x+O(\|x\|^3)\Longrightarrow\nabla\tilde{V}_\infty(x)=\tilde{P}x+O(\|x\|^2)
		\end{align*}
		This implies that $u^*=\underbrace{-\inv{(R+\epsilon M_u+B^T\tilde{P}B)}}_{=:\tilde{K}}B^T\tilde{P}Ax+O(\|x\|^2)$\,.
		By plugging this expression back in the definition of $\tilde{V}_\infty$ given by \ref{RRLB-NMPC-inf-DP} :
		$$\tilde{V}_\infty(x)=x^T(Q+\epsilon M_x+\tilde{K}^T(R+\epsilon M_u)\tilde{K}+A_{\tilde{K}}^T\tilde{P}A_{\tilde{K}})x+O(\|x\|^3)$$
		and by unicity of the Taylor expansion we conclude that $\tilde{P}$ verifies the equation \ref{Riccati}.
		Since $P$ was the unique solution to this equation, we conclude that $P=\tilde{P}$ as wanted.\quad\checkmark

		\item \underline{Step 2 : show the descent property for $\tilde{J}_N$} \newline
		Using the dynamic programming principle for $\tilde{V}_\infty$, we know there exists a feedback control $\mu:\R^{n_x}\to\R^{n_u}$ (given by the solution to \ref{RRLB-NMPC-inf-DP}) such that :
		$$\tilde{V}_\infty(f(x,\mu(x)))-\tilde{V}_\infty(x)+\tilde{l}(x,\mu(x))=0$$
		hence by the approximation shown at last step :
		$$\tilde{F}(f(x,\mu(x)))-\tilde{F}(x)+\tilde{l}(x,\mu(x))=O(\|x\|^3)$$
		Now given $\tilde{\mathbf{x}}(x)$ and $\tilde{\mathbf{u}}(x)$ we can construct some feasible sequences $\mathbf{x}'=(\tilde{x}_1,\dots,\tilde{x}_N,f(\tilde{x}_N,\mu(\tilde{x}_N)))$ and $\mathbf{u}'=(\tilde{u}_1,\dots,\tilde{u}_{N-1},\mu(\tilde{x}_N))$ for the problem \ref{RRLB-NMPC} with initial condition $\tilde{x}_1$\,.
		Then we have :
		$$\tilde{V}_N(\tilde{x}_1)\leq\tilde{J}_N(\mathbf{x}',\mathbf{u}')=\underbrace{\tilde{J}_N(\tilde{\mathbf{x}},\tilde{\mathbf{u}})}_{=\tilde{V}_N(x)}~\underbrace{\underbrace{-\tilde{l}(x,\tilde{u}_0)}_{=O(\|x\|^2)}+\underbrace{\tilde{F}(f(\tilde{x}_N,\mu(\tilde{x}_N)))-\tilde{F}(\tilde{x}_N)+\tilde{l}(\tilde{x}_N,\mu(\tilde{x}_N)) }_{=O(\|\tilde{x}_N\|^3)=O(\|x\|^3)} }_{\leq-c\|x\|^2\text{ locally}}\checkmark$$
		
		\item{\underline{Step 3 : show the quadratic lower and upper bounds of $\tilde{V}_N$}}\newline
		
		The upper bound comes from the fact that the costs $l$ and $F$ are quadratic and that the RRLB functions can also be quadraticallt upper bounded as shown in \ref{RRLB-quadratic-bound}.
		Since these functions are also positive, we can lower bound $\tilde{J}_N$ by $J_N$ and the quadratic lower bound is easy to find given that $Q,R$ and $P$ are positive definite matrices.
	\end{itemize}
\end{proof}

\section*{Appendix}
\printbibliography

\end{document}